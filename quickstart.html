
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Quickstart &#8212; NFFLr 0.1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/nbsphinx-code-cells.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Overview" href="overview.html" />
    <link rel="prev" title="NFFLr documentation" href="index.html" />
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
  <script src="https://code.jquery.com/jquery-1.12.4.min.js" type="text/javascript"></script>
  <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>
  <script async type="text/javascript" id="_fed_an_ua_tag" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=NIST&subagency=github&pua=UA-66610693-1&yt=true&exts=ppsx,pps,f90,sch,rtf,wrl,txz,m1v,xlsm,msi,xsd,f,tif,eps,mpg,xml,pl,xlt,c">
</script>


<script type="text/javascript" src="https://pages.nist.gov/leaveNotice/js/jquery.leaveNotice-nist.min.js"></script>
<script>
$(document).ready(function(){
  // Mark external (non-nist.gov) A tags with class "external"
  //If the adress start with https and ends with nist.gov
  var re_nist = new RegExp('^https?:\/\/((^\/)*\.)*nist\\.gov(\/|$)');
  //Regex to find address that start with https
  var re_absolute_address = new RegExp('^((https?:)?\/\/)');
  $("a").each(function(){
    var url=$(this).attr('href');
    if(re_nist.test(url) || !re_absolute_address.test(url)){
      $(this).addClass('local');
    }else{
      //This a href appears to be external, so tag it
      $(this).addClass('external');
    }
  });
  // Add leaveNotice to external A elements
  $('a.external').leaveNotice();
});
</script>
<link rel="stylesheet" type="text/css" href="https://pages.nist.gov/leaveNotice/css/jquery.leaveNotice.css" />


  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="Quickstart">
<h1>Quickstart<a class="headerlink" href="#Quickstart" title="Permalink to this heading">¶</a></h1>
<section id="Atoms-Data">
<h2><code class="docutils literal notranslate"><span class="pre">Atoms</span></code> Data<a class="headerlink" href="#Atoms-Data" title="Permalink to this heading">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Atoms</span></code> is the primary data structure for atomistic modeling in <code class="docutils literal notranslate"><span class="pre">NFFLr</span></code>. This represents an atomistic system in the same way as <a class="reference external" href="https://spglib.readthedocs.io/en/latest/python-spglib.html#crystal-structure-cell">spglib</a>:</p>
<ul class="simple">
<li><p>a <span class="math notranslate nohighlight">\(3 \times 3\)</span> <code class="docutils literal notranslate"><span class="pre">lattice</span></code> matrix</p></li>
<li><p>an <span class="math notranslate nohighlight">\(N \times 3\)</span> fractional coordinates array <code class="docutils literal notranslate"><span class="pre">positions</span></code></p></li>
<li><p>an array of <code class="docutils literal notranslate"><span class="pre">N</span></code> atomic <code class="docutils literal notranslate"><span class="pre">numbers</span></code></p></li>
</ul>
<p>These variables are stored as PyTorch tensors to facilitate auto-batching, flexible conversion to graph deep learning formats, and automatic differentiation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">nfflr.data.atoms</span> <span class="kn">import</span> <span class="n">Atoms</span>

<span class="n">lattice</span> <span class="o">=</span> <span class="mf">4.1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
<span class="n">numbers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">24</span><span class="p">,</span> <span class="mi">22</span><span class="p">])</span>
<span class="n">atoms</span> <span class="o">=</span> <span class="n">Atoms</span><span class="p">(</span><span class="n">lattice</span><span class="p">,</span> <span class="n">positions</span><span class="p">,</span> <span class="n">numbers</span><span class="p">)</span>
<span class="n">atoms</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Atoms(lattice=tensor([[4.1000, 0.0000, 0.0000],
        [0.0000, 4.1000, 0.0000],
        [0.0000, 0.0000, 4.1000]]), positions=tensor([[0.0000, 0.0000, 0.0000],
        [0.5000, 0.5000, 0.5000]]), numbers=tensor([24, 22]), _batch_num_atoms=None)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ase</span> <span class="kn">import</span> <span class="n">Atoms</span> <span class="k">as</span> <span class="n">AseAtoms</span>
<span class="kn">from</span> <span class="nn">ase.visualize.plot</span> <span class="kn">import</span> <span class="n">plot_atoms</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ase_atoms</span> <span class="o">=</span> <span class="n">AseAtoms</span><span class="p">(</span><span class="n">scaled_positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span> <span class="n">numbers</span><span class="o">=</span><span class="n">numbers</span><span class="p">,</span> <span class="n">cell</span><span class="o">=</span><span class="n">lattice</span><span class="p">)</span>
<span class="n">plot_atoms</span><span class="p">(</span><span class="n">ase_atoms</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">radii</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;10x,20y,0z&quot;</span><span class="p">),</span> <span class="n">show_unit_cell</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/quickstart_3_0.png" src="_images/quickstart_3_0.png" />
</div>
</div>
</section>
<section id="Models">
<h2>Models<a class="headerlink" href="#Models" title="Permalink to this heading">¶</a></h2>
<section id="Common-model-interface">
<h3>Common model interface<a class="headerlink" href="#Common-model-interface" title="Permalink to this heading">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">NFFLr</span></code> models are PyTorch modules for modeling properties of atomistic systems.</p>
<p>Different modeling approaches use a variety of input representations; <code class="docutils literal notranslate"><span class="pre">NFFLr</span></code> aims to simplify exploratory research by providing a common modeling interface, where all models internally transform <code class="docutils literal notranslate"><span class="pre">Atoms</span></code> inputs to their native input representation, <em>e.g.</em> the <a class="reference external" href="https://docs.dgl.ai/api/python/dgl.DGLGraph.html">DGLGraph</a> structure expected by <code class="docutils literal notranslate"><span class="pre">ALIGNN</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nfflr.models.gnn</span> <span class="kn">import</span> <span class="n">alignn</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">alignn</span><span class="o">.</span><span class="n">ALIGNNConfig</span><span class="p">(</span><span class="n">alignn_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gcn_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">alignn_model</span> <span class="o">=</span> <span class="n">alignn</span><span class="o">.</span><span class="n">ALIGNN</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">alignn_model</span><span class="p">(</span><span class="n">atoms</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
construct graph
tensor(0.3651)
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">NFFLr</span></code> also transparently converts inputs from common atomistic modeling libraries, such as jarvis and ase. This is an experimental feature that is currently implemented with the <a class="reference external" href="https://github.com/beartype/plum#plum-multiple-dispatch-in-python">plum multiple dispatch library</a>. For example, calling <code class="docutils literal notranslate"><span class="pre">alignn_model</span></code> on an <code class="docutils literal notranslate"><span class="pre">ase.Atoms</span></code> structure automatically converts the data to <code class="docutils literal notranslate"><span class="pre">nfflr.Atoms</span></code> and then to the <code class="docutils literal notranslate"><span class="pre">ALIGNN</span></code> <code class="docutils literal notranslate"><span class="pre">DGLGraph</span></code> format:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">alignn_model</span><span class="p">(</span><span class="n">ase_atoms</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
convert
construct graph
tensor(0.3651)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
</pre></div></div>
</div>
</section>
<section id="Force-field-models">
<h3>Force field models<a class="headerlink" href="#Force-field-models" title="Permalink to this heading">¶</a></h3>
<p>Enabling the <code class="docutils literal notranslate"><span class="pre">compute_forces</span></code> model configuration field will cause the model to compute both a scalar property prediction and its (negative) gradient with respect to the (cartesian) atomic coordinates - <em>i.e.</em> the force components on each atom.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">alignn</span><span class="o">.</span><span class="n">ALIGNNConfig</span><span class="p">(</span>
    <span class="n">alignn_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">gcn_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">compute_forces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">alignn_model</span> <span class="o">=</span> <span class="n">alignn</span><span class="o">.</span><span class="n">ALIGNN</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span class="n">alignn_model</span><span class="p">(</span><span class="n">atoms</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
construct graph
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;total_energy&#39;: tensor(-0.2599, grad_fn=&lt;SqueezeBackward0&gt;),
 &#39;forces&#39;: tensor([[-1.3188e-06, -1.6764e-07,  2.0303e-07],
         [ 5.7369e-07,  4.3586e-07, -3.9674e-07]], grad_fn=&lt;MulBackward0&gt;)}
</pre></div></div>
</div>
</section>
<section id="input-representations">
<h3>input representations<a class="headerlink" href="#input-representations" title="Permalink to this heading">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">NFFLr</span></code> also allows to directly provide inputs to models in the native input representation expected by the model. This facilitates efficient precomputation and caching during training. For example, <code class="docutils literal notranslate"><span class="pre">ALIGNN</span></code> requires <code class="docutils literal notranslate"><span class="pre">DGLGraph</span></code> inputs with node features <code class="docutils literal notranslate"><span class="pre">atomic_number</span></code> and edge features <code class="docutils literal notranslate"><span class="pre">r</span></code> (the bond vectors pointing from atoms to their neighbors).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nfflr.data.graph</span> <span class="kn">import</span> <span class="n">periodic_radius_graph</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">periodic_radius_graph</span><span class="p">(</span><span class="n">atoms</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">g</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Graph(num_nodes=2, num_edges=52,
      ndata_schemes={&#39;Xfrac&#39;: Scheme(shape=(3,), dtype=torch.float32), &#39;coord&#39;: Scheme(shape=(3,), dtype=torch.float32), &#39;atomic_number&#39;: Scheme(shape=(), dtype=torch.int32)}
      edata_schemes={&#39;r&#39;: Scheme(shape=(3,), dtype=torch.float32)})
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alignn_model</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;total_energy&#39;: tensor(0.3146, grad_fn=&lt;SqueezeBackward0&gt;),
 &#39;forces&#39;: tensor([[-6.5804e-05, -5.1502e-05,  5.5355e-05],
         [ 4.2915e-05,  4.5771e-05, -5.2891e-05]], grad_fn=&lt;MulBackward0&gt;)}
</pre></div></div>
</div>
</section>
</section>
<section id="Training-utilities">
<h2>Training utilities<a class="headerlink" href="#Training-utilities" title="Permalink to this heading">¶</a></h2>
<section id="AtomsDataset">
<h3><code class="docutils literal notranslate"><span class="pre">AtomsDataset</span></code><a class="headerlink" href="#AtomsDataset" title="Permalink to this heading">¶</a></h3>
<p>NFFLr makes it easy to load data and transform it into various formats.</p>
<p>The primary ways of interacting with data are <code class="docutils literal notranslate"><span class="pre">Atoms</span></code> and <code class="docutils literal notranslate"><span class="pre">AtomsDataset</span></code>, which is a <a class="reference external" href="https://pytorch.org/docs/stable/data.html">PyTorch DataSet</a> that returns <code class="docutils literal notranslate"><span class="pre">Atoms</span></code> instances. The most convenient way to get started is with a <a class="reference external" href="https://jarvis-tools.readthedocs.io/en/master/databases.html">named Jarvis dataset</a>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nfflr.data.dataset</span> <span class="kn">import</span> <span class="n">AtomsDataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">AtomsDataset</span><span class="p">(</span><span class="s2">&quot;dft_3d&quot;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;formation_energy_peratom&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
dataset_name=&#39;dft_3d&#39;
Obtaining 3D dataset 76k ...
Reference:https://www.nature.com/articles/s41524-020-00440-1
Other versions:https://doi.org/10.6084/m9.figshare.6815699
Loading the zipfile...
Loading completed.
</pre></div></div>
</div>
<p>The dataset yields a tuple of an <code class="docutils literal notranslate"><span class="pre">Atoms</span></code> instance and the target value, <em>e.g.,</em> <code class="docutils literal notranslate"><span class="pre">target=&quot;formation_energy_peratom&quot;</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">atoms</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">atoms</span><span class="o">.</span><span class="n">lattice</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">atoms</span><span class="o">.</span><span class="n">positions</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">atoms</span><span class="o">.</span><span class="n">numbers</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">target</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
atoms.lattice=tensor([[3.5669, 0.0000, -0.0000],
        [0.0000, 3.5669, -0.0000],
        [-0.0000, -0.0000, 9.3971]])
atoms.positions=tensor([[0.7500, 0.7500, 0.7849],
        [0.2500, 0.2500, 0.2151],
        [0.2500, 0.7500, 0.5000],
        [0.7500, 0.2500, 0.5000],
        [0.2500, 0.7500, 0.0000],
        [0.7500, 0.2500, 0.0000],
        [0.7500, 0.7500, 0.3075],
        [0.2500, 0.2500, 0.6925]])
atoms.numbers=tensor([22, 22, 29, 29, 14, 14, 33, 33], dtype=torch.int32)
target=tensor(-0.4276)
</pre></div></div>
</div>
<p>Internally, <code class="docutils literal notranslate"><span class="pre">AtomsDataset</span></code> uses a <a class="reference external" href="https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe">pandas dataframe</a> to store the datasets, so any key in the jarvis dataset is a valid <code class="docutils literal notranslate"><span class="pre">target</span></code>. For example, <code class="docutils literal notranslate"><span class="pre">dft_3d</span></code> contains a large number of target properties, including some non-scalar quantities:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_cols</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;jid&quot;</span><span class="p">,</span> <span class="s2">&quot;formula&quot;</span><span class="p">,</span> <span class="s2">&quot;formation_energy_peratom&quot;</span><span class="p">,</span> <span class="s2">&quot;optb88vdw_bandgap&quot;</span><span class="p">,</span> <span class="s2">&quot;elastic_tensor&quot;</span><span class="p">)</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">selected_cols</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>jid</th>
      <th>formula</th>
      <th>formation_energy_peratom</th>
      <th>optb88vdw_bandgap</th>
      <th>elastic_tensor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>JVASP-90856</td>
      <td>TiCuSiAs</td>
      <td>-0.42762</td>
      <td>0.000</td>
      <td>na</td>
    </tr>
    <tr>
      <th>1</th>
      <td>JVASP-86097</td>
      <td>DyB6</td>
      <td>-0.41596</td>
      <td>0.000</td>
      <td>na</td>
    </tr>
    <tr>
      <th>2</th>
      <td>JVASP-64906</td>
      <td>Be2OsRu</td>
      <td>0.04847</td>
      <td>0.000</td>
      <td>na</td>
    </tr>
    <tr>
      <th>3</th>
      <td>JVASP-98225</td>
      <td>KBi</td>
      <td>-0.44140</td>
      <td>0.472</td>
      <td>na</td>
    </tr>
    <tr>
      <th>4</th>
      <td>JVASP-10</td>
      <td>VSe2</td>
      <td>-0.71026</td>
      <td>0.000</td>
      <td>[[136.4, 27.8, 17.5, 0.0, -5.5, 0.0], [27.8, 1...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We can change the target column, but missing values currently need to be handled manually.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;elastic_tensor&quot;</span>
<span class="n">atoms</span><span class="p">,</span> <span class="n">elastic_tensor</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
<span class="n">elastic_tensor</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[136.4000,  27.8000,  17.5000,   0.0000,  -5.5000,   0.0000],
        [ 27.8000, 136.4000,  17.5000,   0.0000,   5.5000,   0.0000],
        [ 17.5000,  17.5000,  40.7000,   0.0000,   0.0000,   0.0000],
        [  0.0000,   0.0000,   0.0000,  54.3000,   0.0000,  -5.5000],
        [ -5.5000,   5.5000,   0.0000,   0.0000,  13.7000,   0.0000],
        [  0.0000,   0.0000,   0.0000,  -5.5000,   0.0000,  13.7000]])
</pre></div></div>
</div>
</section>
</section>
<section id="Force-field-datasets">
<h2>Force field datasets<a class="headerlink" href="#Force-field-datasets" title="Permalink to this heading">¶</a></h2>
<p>Force field datasets like <code class="docutils literal notranslate"><span class="pre">mlearn</span></code>, <code class="docutils literal notranslate"><span class="pre">alignn_ff_db</span></code>, and <code class="docutils literal notranslate"><span class="pre">m3gnet</span></code> have a special target key <code class="docutils literal notranslate"><span class="pre">target=&quot;energy_and_forces&quot;</span></code> that configure <code class="docutils literal notranslate"><span class="pre">AtomsDataset</span></code> to return a dictionary of target values containing the total energy of the atomic configuration, the forces, and the stresses if they are available.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">AtomsDataset</span><span class="p">(</span><span class="s2">&quot;mlearn&quot;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;energy_and_forces&quot;</span><span class="p">)</span>
<span class="n">atoms</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">target</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
dataset_name=&#39;mlearn&#39;
Obtaining mlearn dataset 1730...
Reference:https://github.com/materialsvirtuallab/mlearn
Loading the zipfile...
Loading completed.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;energy&#39;: tensor(-64656.0625),
 &#39;forces&#39;: tensor([[-1.9282e-01, -1.8793e+00, -6.6374e-01],
         [-8.2543e-03, -2.0313e-01,  3.6808e-01],
         [-5.5372e-01, -1.4736e+00,  1.2997e+00],
         [ 4.5678e-01,  5.1175e-01, -1.0934e+00],
         [-1.6499e+00, -1.6259e+00,  4.5255e-01],
         [-1.6698e-01,  6.8080e-01,  6.7749e-01],
         [ 3.6802e-02, -3.1423e+00, -2.0166e+00],
         [-1.0730e-01, -3.5780e-01,  1.1357e+00],
         [-1.9132e-01,  5.1381e-01,  3.4296e-01],
         [ 2.0090e+00,  1.5143e+00, -3.5578e-01],
         [-1.7128e-01, -2.7808e+00, -1.4215e+00],
         [-9.3987e-01, -1.6757e-02,  7.9322e-01],
         [ 3.7190e-01, -9.0627e-01, -5.2933e-01],
         [ 5.6458e-01, -9.6833e-01, -7.0043e-01],
         [-4.5756e-01, -6.5868e-02, -3.7038e-01],
         [-1.2044e+00,  6.3979e-01,  7.5036e-01],
         [-1.5743e+00,  6.4479e-02, -6.7272e-01],
         [-9.8223e-01, -9.5903e-02, -8.7198e-01],
         [ 4.9518e-01, -2.7982e-01, -4.6208e-01],
         [ 3.3000e-01,  1.7643e-01,  2.0947e+00],
         [ 3.3517e-01,  1.4522e+00,  3.6359e-01],
         [-4.4930e-01, -3.1648e-01,  2.1246e-01],
         [-5.8361e-01,  1.0337e+00, -1.0099e+00],
         [ 1.4334e+00,  1.4563e+00,  4.8775e-01],
         [-1.2193e+00, -1.8368e-01,  1.7678e-01],
         [-1.8822e-02, -3.3724e-01,  5.0373e-01],
         [ 9.7925e-01,  3.4629e-01,  2.7126e-01],
         [ 1.3972e+00,  1.0313e-01,  2.1936e+00],
         [ 1.4154e+00,  1.0657e+00,  5.6893e-01],
         [-5.3909e-01,  6.2667e-01,  7.9585e-01],
         [-8.0468e-02,  9.3723e-01, -1.7657e+00],
         [ 6.4826e-01,  1.3950e-03, -1.1809e+00],
         [ 1.7236e+00,  5.0571e-01,  2.0909e-01],
         [-6.3469e-01,  3.2798e+00,  1.3690e+00],
         [-2.8363e-01,  1.3372e+00, -3.8005e-01],
         [-1.0848e+00, -5.7622e-01, -6.1141e-01],
         [-1.8884e+00,  5.1697e-01, -1.0889e-01],
         [-5.3894e-01,  2.1740e+00,  2.2013e+00],
         [ 1.5727e+00, -9.5217e-01,  9.6934e-01],
         [ 3.8191e-01,  3.4829e-01,  1.2664e+00],
         [-1.1411e+00,  1.2328e+00,  1.2866e+00],
         [ 1.1776e+00,  7.2366e-01, -1.5056e+00],
         [-1.3455e+00, -4.8714e-01,  4.1776e-01],
         [ 2.7808e-01, -1.4488e-01,  1.2792e+00],
         [-2.0664e-01,  1.4243e+00,  1.2686e+00],
         [ 1.3897e+00,  7.7333e-01, -8.4011e-01],
         [-7.0459e-01, -2.1634e+00,  1.0630e+00],
         [-9.9009e-01, -6.2214e-01, -9.4072e-03],
         [ 3.3802e-01,  3.1611e-01,  1.3336e-01],
         [-1.2308e+00, -2.7998e-01, -9.0719e-01],
         [ 1.5169e+00, -6.4886e-01, -1.4431e+00],
         [ 2.3966e+00,  1.3065e+00,  3.9503e-01],
         [ 4.8711e-01,  2.6996e-03,  5.6954e-01],
         [ 3.0038e-02,  9.8048e-01,  9.6736e-02],
         [-2.8896e-01,  6.9839e-01,  1.1865e-01],
         [-7.0303e-01,  1.5889e+00,  1.0517e+00],
         [ 1.4835e+00, -7.5193e-01, -4.8107e-01],
         [ 4.3507e-01, -7.6680e-01, -7.6512e-01],
         [ 1.6324e+00, -9.0497e-01, -1.7391e-01],
         [-7.7163e-01,  8.8480e-01, -1.0546e-01],
         [ 1.5508e+00, -1.4519e-01, -6.3183e-01],
         [ 1.4062e+00,  4.8017e-01,  2.4209e-01],
         [-8.2076e-01, -1.1055e+00, -3.7652e-01],
         [-1.7866e+00, -1.0725e-01, -7.5774e-01],
         [ 6.6219e-01, -1.1061e+00,  6.6820e-01],
         [ 4.5689e-01, -3.1297e-01,  5.2079e-01],
         [-2.3750e-01,  1.6904e+00, -7.2430e-01],
         [ 1.5449e+00,  1.4885e+00, -5.6164e-01],
         [ 1.6403e+00, -1.3929e+00, -1.3473e-01],
         [-5.0026e-01, -7.1965e-01, -6.3690e-01],
         [ 1.8875e-01, -8.0416e-01,  1.0578e+00],
         [ 7.4767e-01, -2.7263e-01,  1.0396e-01],
         [ 1.0797e+00,  6.2834e-01, -1.0441e+00],
         [-9.1592e-01, -1.0053e+00, -1.6651e-01],
         [-2.4538e-01,  1.1315e+00, -2.5051e-01],
         [-2.6349e-01, -3.9915e-01,  5.2209e-01],
         [ 8.3324e-01,  2.9588e-02,  4.1156e-01],
         [ 1.3736e-01,  5.2689e-01, -7.6983e-01],
         [ 1.8699e+00, -5.6415e-01, -1.2089e+00],
         [-8.2056e-01, -5.2394e-01, -1.0657e-01],
         [-1.3969e-01, -2.1350e-01,  2.1012e-01],
         [-8.5827e-01, -2.9145e-01, -8.8987e-02],
         [-2.7861e-01, -6.4112e-01,  2.7514e-01],
         [-7.0377e-01, -1.6119e-01, -1.6974e-02],
         [-4.9227e-01, -5.5502e-01, -1.6419e+00],
         [ 1.3265e+00,  5.1135e-01, -2.0431e-01],
         [-6.3025e-01, -4.0777e-01, -7.4116e-01],
         [-2.7982e+00, -8.6561e-01,  7.2870e-01],
         [ 4.4176e-01, -6.1487e-01, -1.5266e+00],
         [-8.2469e-01, -1.5254e+00,  2.2129e-01],
         [-4.1837e-01,  4.5957e-01, -9.3009e-01],
         [-1.3448e+00, -3.8741e-01,  5.7946e-01],
         [-3.5803e-02, -4.9431e-01, -3.3611e-01],
         [ 1.3890e+00, -2.3396e-01, -5.8913e-01],
         [ 4.6561e-01, -1.6739e+00, -5.8580e-01],
         [-5.4732e-02,  1.2076e+00, -6.2845e-01],
         [-1.9202e+00,  2.6483e-01, -4.7163e-01],
         [ 2.3382e-01, -1.9371e-01,  8.8642e-01],
         [-5.4136e-02,  7.5257e-01, -7.5428e-01],
         [-1.2954e+00, -8.2409e-01, -2.3798e-01],
         [ 2.2413e-01, -5.5878e-02, -5.6709e-01],
         [ 1.0508e+00,  4.7083e-01,  1.0494e+00],
         [ 1.1418e+00,  3.9075e-01,  2.2798e-01],
         [-1.6860e+00,  8.3186e-01,  7.9992e-01],
         [-1.1271e+00,  7.7508e-02,  9.2828e-01],
         [-1.0157e+00,  5.2795e-01, -1.9179e-01],
         [ 4.6428e-01, -1.5829e-01,  7.1079e-01]]),
 &#39;stresses&#39;: tensor([[41.4064,  5.9450, -4.7715],
         [ 5.9450, 41.1876,  1.0425],
         [-4.7715,  1.0425, 51.0653]])}
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="kn">from</span> <span class="nn">nfflr.data.graph</span> <span class="kn">import</span> <span class="n">periodic_adaptive_radius_graph</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(Atoms(lattice=tensor([[10.5241,  0.0000,  0.0000],
         [ 0.0000, 10.5241,  0.0000],
         [ 0.0000,  0.0000, 10.5241]]), positions=tensor([[8.8610e-03, 1.2966e-02, 3.4177e-01],
         [1.1860e-03, 9.9954e-01, 6.5278e-01],
         [1.5720e-03, 3.4240e-01, 9.8957e-01],
         [9.9629e-01, 3.3764e-01, 3.4630e-01],
         [9.3410e-03, 3.4059e-01, 6.6076e-01],
         [9.9993e-01, 6.5754e-01, 1.9600e-04],
         [4.7140e-03, 6.9225e-01, 3.4508e-01],
         [9.8893e-01, 6.6955e-01, 6.6091e-01],
         [3.3666e-01, 9.9502e-01, 1.4700e-04],
         [3.1948e-01, 9.9440e-01, 3.3301e-01],
         [3.4375e-01, 2.9278e-02, 6.6325e-01],
         [3.3291e-01, 3.2844e-01, 9.8932e-01],
         [3.2360e-01, 3.5171e-01, 3.3943e-01],
         [3.2243e-01, 3.3939e-01, 6.6961e-01],
         [3.3457e-01, 6.7072e-01, 9.9313e-01],
         [3.4607e-01, 6.5817e-01, 3.3440e-01],
         [3.4433e-01, 6.6961e-01, 6.7335e-01],
         [6.8091e-01, 9.9228e-01, 2.0310e-03],
         [6.6933e-01, 5.4890e-03, 3.3881e-01],
         [6.7000e-01, 9.9714e-01, 6.5166e-01],
         [6.6816e-01, 3.1639e-01, 9.9623e-01],
         [6.6920e-01, 3.3440e-01, 3.2128e-01],
         [6.7513e-01, 3.3324e-01, 6.7626e-01],
         [6.4743e-01, 6.5551e-01, 9.9501e-01],
         [6.7395e-01, 6.6333e-01, 3.2915e-01],
         [6.6407e-01, 6.7044e-01, 6.7311e-01],
         [9.9937e-01, 1.5280e-01, 1.6188e-01],
         [9.8534e-01, 1.6818e-01, 4.8469e-01],
         [9.9490e-01, 1.5352e-01, 8.2297e-01],
         [9.9878e-01, 4.9626e-01, 1.5909e-01],
         [9.9433e-01, 5.0090e-01, 5.1118e-01],
         [9.8346e-01, 5.0409e-01, 8.4404e-01],
         [9.7864e-01, 8.2658e-01, 1.6211e-01],
         [4.6760e-03, 8.1529e-01, 5.0061e-01],
         [5.7320e-03, 8.1913e-01, 8.3802e-01],
         [3.4415e-01, 1.8079e-01, 1.7886e-01],
         [3.5898e-01, 1.6424e-01, 4.9430e-01],
         [3.2298e-01, 1.5092e-01, 8.2085e-01],
         [3.1217e-01, 5.0474e-01, 1.5592e-01],
         [3.3188e-01, 5.0162e-01, 5.0273e-01],
         [3.4417e-01, 4.8906e-01, 8.2149e-01],
         [3.2573e-01, 8.2679e-01, 1.7796e-01],
         [3.5701e-01, 8.4234e-01, 4.9825e-01],
         [3.3547e-01, 8.4445e-01, 8.1719e-01],
         [6.7534e-01, 1.5154e-01, 1.5216e-01],
         [6.6919e-01, 1.6766e-01, 5.0290e-01],
         [6.8222e-01, 1.7791e-01, 8.2511e-01],
         [6.6884e-01, 5.0351e-01, 1.6370e-01],
         [6.5816e-01, 4.9164e-01, 5.0023e-01],
         [6.7682e-01, 5.0029e-01, 8.3706e-01],
         [6.5419e-01, 8.3977e-01, 1.8008e-01],
         [6.4563e-01, 8.1842e-01, 4.9773e-01],
         [6.6049e-01, 8.4283e-01, 8.2772e-01],
         [1.5955e-01, 9.8473e-01, 1.6565e-01],
         [1.7511e-01, 9.8687e-01, 5.0398e-01],
         [1.6777e-01, 9.8665e-01, 8.2410e-01],
         [1.4428e-01, 3.3899e-01, 1.7697e-01],
         [1.6374e-01, 3.4594e-01, 5.0575e-01],
         [1.4702e-01, 3.3920e-01, 8.3203e-01],
         [1.6570e-01, 6.6008e-01, 1.7097e-01],
         [1.6167e-01, 6.7040e-01, 5.2098e-01],
         [1.5403e-01, 6.5813e-01, 8.2990e-01],
         [5.0408e-01, 1.4162e-02, 1.7293e-01],
         [5.2003e-01, 4.9100e-03, 5.0066e-01],
         [5.0272e-01, 2.1127e-02, 8.2948e-01],
         [4.9261e-01, 3.4657e-01, 1.6117e-01],
         [5.0572e-01, 3.2500e-01, 5.1147e-01],
         [4.8274e-01, 3.0837e-01, 8.3192e-01],
         [4.8263e-01, 6.7486e-01, 1.6718e-01],
         [5.0145e-01, 6.6365e-01, 5.0892e-01],
         [4.9795e-01, 6.8452e-01, 8.2549e-01],
         [8.2999e-01, 9.9344e-01, 1.7305e-01],
         [8.2539e-01, 9.8901e-01, 5.0311e-01],
         [8.4646e-01, 8.1600e-04, 8.2843e-01],
         [8.4071e-01, 3.1688e-01, 1.6089e-01],
         [8.2948e-01, 3.3842e-01, 4.9434e-01],
         [8.3571e-01, 3.3019e-01, 8.3055e-01],
         [8.3109e-01, 6.5910e-01, 1.7131e-01],
         [8.0698e-01, 6.6579e-01, 5.1274e-01],
         [8.3373e-01, 6.7427e-01, 8.3443e-01],
         [1.6433e-01, 1.6361e-01, 9.9668e-01],
         [1.8062e-01, 1.7457e-01, 3.4169e-01],
         [1.6492e-01, 1.7264e-01, 6.5071e-01],
         [1.7447e-01, 5.0035e-01, 9.9062e-01],
         [1.6301e-01, 5.1862e-01, 3.5785e-01],
         [1.5166e-01, 5.0187e-01, 6.7502e-01],
         [1.7105e-01, 8.3375e-01, 6.3730e-03],
         [1.9458e-01, 8.2731e-01, 3.4052e-01],
         [1.6183e-01, 8.3334e-01, 6.7885e-01],
         [5.0510e-01, 1.7601e-01, 2.8660e-03],
         [5.1288e-01, 1.7028e-01, 3.3753e-01],
         [5.2357e-01, 1.7098e-01, 6.6266e-01],
         [4.9352e-01, 5.0132e-01, 9.9745e-01],
         [4.9040e-01, 4.9813e-01, 3.3980e-01],
         [5.0355e-01, 5.1290e-01, 6.7713e-01],
         [5.0030e-01, 8.2876e-01, 7.7860e-03],
         [5.1234e-01, 8.3157e-01, 3.3580e-01],
         [4.9850e-01, 8.4694e-01, 6.6235e-01],
         [8.4987e-01, 1.4414e-01, 2.8420e-03],
         [8.3989e-01, 1.7320e-01, 3.2958e-01],
         [8.3715e-01, 1.6773e-01, 6.6364e-01],
         [8.1826e-01, 4.9139e-01, 9.9657e-01],
         [8.2342e-01, 4.9526e-01, 3.3035e-01],
         [8.4335e-01, 4.9038e-01, 6.6325e-01],
         [8.4744e-01, 8.3644e-01, 9.8641e-01],
         [8.3764e-01, 8.2921e-01, 3.4132e-01],
         [8.2658e-01, 8.3450e-01, 6.6057e-01]]), numbers=tensor([28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,
         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,
         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,
         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,
         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,
         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28],
        dtype=torch.int32)),
 {&#39;energy&#39;: tensor(-64656.0625),
  &#39;forces&#39;: tensor([[-1.9282e-01, -1.8793e+00, -6.6374e-01],
          [-8.2543e-03, -2.0313e-01,  3.6808e-01],
          [-5.5372e-01, -1.4736e+00,  1.2997e+00],
          [ 4.5678e-01,  5.1175e-01, -1.0934e+00],
          [-1.6499e+00, -1.6259e+00,  4.5255e-01],
          [-1.6698e-01,  6.8080e-01,  6.7749e-01],
          [ 3.6802e-02, -3.1423e+00, -2.0166e+00],
          [-1.0730e-01, -3.5780e-01,  1.1357e+00],
          [-1.9132e-01,  5.1381e-01,  3.4296e-01],
          [ 2.0090e+00,  1.5143e+00, -3.5578e-01],
          [-1.7128e-01, -2.7808e+00, -1.4215e+00],
          [-9.3987e-01, -1.6757e-02,  7.9322e-01],
          [ 3.7190e-01, -9.0627e-01, -5.2933e-01],
          [ 5.6458e-01, -9.6833e-01, -7.0043e-01],
          [-4.5756e-01, -6.5868e-02, -3.7038e-01],
          [-1.2044e+00,  6.3979e-01,  7.5036e-01],
          [-1.5743e+00,  6.4479e-02, -6.7272e-01],
          [-9.8223e-01, -9.5903e-02, -8.7198e-01],
          [ 4.9518e-01, -2.7982e-01, -4.6208e-01],
          [ 3.3000e-01,  1.7643e-01,  2.0947e+00],
          [ 3.3517e-01,  1.4522e+00,  3.6359e-01],
          [-4.4930e-01, -3.1648e-01,  2.1246e-01],
          [-5.8361e-01,  1.0337e+00, -1.0099e+00],
          [ 1.4334e+00,  1.4563e+00,  4.8775e-01],
          [-1.2193e+00, -1.8368e-01,  1.7678e-01],
          [-1.8822e-02, -3.3724e-01,  5.0373e-01],
          [ 9.7925e-01,  3.4629e-01,  2.7126e-01],
          [ 1.3972e+00,  1.0313e-01,  2.1936e+00],
          [ 1.4154e+00,  1.0657e+00,  5.6893e-01],
          [-5.3909e-01,  6.2667e-01,  7.9585e-01],
          [-8.0468e-02,  9.3723e-01, -1.7657e+00],
          [ 6.4826e-01,  1.3950e-03, -1.1809e+00],
          [ 1.7236e+00,  5.0571e-01,  2.0909e-01],
          [-6.3469e-01,  3.2798e+00,  1.3690e+00],
          [-2.8363e-01,  1.3372e+00, -3.8005e-01],
          [-1.0848e+00, -5.7622e-01, -6.1141e-01],
          [-1.8884e+00,  5.1697e-01, -1.0889e-01],
          [-5.3894e-01,  2.1740e+00,  2.2013e+00],
          [ 1.5727e+00, -9.5217e-01,  9.6934e-01],
          [ 3.8191e-01,  3.4829e-01,  1.2664e+00],
          [-1.1411e+00,  1.2328e+00,  1.2866e+00],
          [ 1.1776e+00,  7.2366e-01, -1.5056e+00],
          [-1.3455e+00, -4.8714e-01,  4.1776e-01],
          [ 2.7808e-01, -1.4488e-01,  1.2792e+00],
          [-2.0664e-01,  1.4243e+00,  1.2686e+00],
          [ 1.3897e+00,  7.7333e-01, -8.4011e-01],
          [-7.0459e-01, -2.1634e+00,  1.0630e+00],
          [-9.9009e-01, -6.2214e-01, -9.4072e-03],
          [ 3.3802e-01,  3.1611e-01,  1.3336e-01],
          [-1.2308e+00, -2.7998e-01, -9.0719e-01],
          [ 1.5169e+00, -6.4886e-01, -1.4431e+00],
          [ 2.3966e+00,  1.3065e+00,  3.9503e-01],
          [ 4.8711e-01,  2.6996e-03,  5.6954e-01],
          [ 3.0038e-02,  9.8048e-01,  9.6736e-02],
          [-2.8896e-01,  6.9839e-01,  1.1865e-01],
          [-7.0303e-01,  1.5889e+00,  1.0517e+00],
          [ 1.4835e+00, -7.5193e-01, -4.8107e-01],
          [ 4.3507e-01, -7.6680e-01, -7.6512e-01],
          [ 1.6324e+00, -9.0497e-01, -1.7391e-01],
          [-7.7163e-01,  8.8480e-01, -1.0546e-01],
          [ 1.5508e+00, -1.4519e-01, -6.3183e-01],
          [ 1.4062e+00,  4.8017e-01,  2.4209e-01],
          [-8.2076e-01, -1.1055e+00, -3.7652e-01],
          [-1.7866e+00, -1.0725e-01, -7.5774e-01],
          [ 6.6219e-01, -1.1061e+00,  6.6820e-01],
          [ 4.5689e-01, -3.1297e-01,  5.2079e-01],
          [-2.3750e-01,  1.6904e+00, -7.2430e-01],
          [ 1.5449e+00,  1.4885e+00, -5.6164e-01],
          [ 1.6403e+00, -1.3929e+00, -1.3473e-01],
          [-5.0026e-01, -7.1965e-01, -6.3690e-01],
          [ 1.8875e-01, -8.0416e-01,  1.0578e+00],
          [ 7.4767e-01, -2.7263e-01,  1.0396e-01],
          [ 1.0797e+00,  6.2834e-01, -1.0441e+00],
          [-9.1592e-01, -1.0053e+00, -1.6651e-01],
          [-2.4538e-01,  1.1315e+00, -2.5051e-01],
          [-2.6349e-01, -3.9915e-01,  5.2209e-01],
          [ 8.3324e-01,  2.9588e-02,  4.1156e-01],
          [ 1.3736e-01,  5.2689e-01, -7.6983e-01],
          [ 1.8699e+00, -5.6415e-01, -1.2089e+00],
          [-8.2056e-01, -5.2394e-01, -1.0657e-01],
          [-1.3969e-01, -2.1350e-01,  2.1012e-01],
          [-8.5827e-01, -2.9145e-01, -8.8987e-02],
          [-2.7861e-01, -6.4112e-01,  2.7514e-01],
          [-7.0377e-01, -1.6119e-01, -1.6974e-02],
          [-4.9227e-01, -5.5502e-01, -1.6419e+00],
          [ 1.3265e+00,  5.1135e-01, -2.0431e-01],
          [-6.3025e-01, -4.0777e-01, -7.4116e-01],
          [-2.7982e+00, -8.6561e-01,  7.2870e-01],
          [ 4.4176e-01, -6.1487e-01, -1.5266e+00],
          [-8.2469e-01, -1.5254e+00,  2.2129e-01],
          [-4.1837e-01,  4.5957e-01, -9.3009e-01],
          [-1.3448e+00, -3.8741e-01,  5.7946e-01],
          [-3.5803e-02, -4.9431e-01, -3.3611e-01],
          [ 1.3890e+00, -2.3396e-01, -5.8913e-01],
          [ 4.6561e-01, -1.6739e+00, -5.8580e-01],
          [-5.4732e-02,  1.2076e+00, -6.2845e-01],
          [-1.9202e+00,  2.6483e-01, -4.7163e-01],
          [ 2.3382e-01, -1.9371e-01,  8.8642e-01],
          [-5.4136e-02,  7.5257e-01, -7.5428e-01],
          [-1.2954e+00, -8.2409e-01, -2.3798e-01],
          [ 2.2413e-01, -5.5878e-02, -5.6709e-01],
          [ 1.0508e+00,  4.7083e-01,  1.0494e+00],
          [ 1.1418e+00,  3.9075e-01,  2.2798e-01],
          [-1.6860e+00,  8.3186e-01,  7.9992e-01],
          [-1.1271e+00,  7.7508e-02,  9.2828e-01],
          [-1.0157e+00,  5.2795e-01, -1.9179e-01],
          [ 4.6428e-01, -1.5829e-01,  7.1079e-01]]),
  &#39;stresses&#39;: tensor([[41.4064,  5.9450, -4.7715],
          [ 5.9450, 41.1876,  1.0425],
          [-4.7715,  1.0425, 51.0653]])})
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">NFFLr</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Atoms-Data"><code class="docutils literal notranslate"><span class="pre">Atoms</span></code> Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Models">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Common-model-interface">Common model interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Force-field-models">Force field models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#input-representations">input representations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Training-utilities">Training utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#AtomsDataset"><code class="docutils literal notranslate"><span class="pre">AtomsDataset</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Force-field-datasets">Force field datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="atoms.html">Atoms</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">NFFLr documentation</a></li>
      <li>Next: <a href="overview.html" title="next chapter">Overview</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Brian DeCost.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/quickstart.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>