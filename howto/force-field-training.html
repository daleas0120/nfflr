
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Force field example &#8212; nfflr 0.2.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=c480a563"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'howto/force-field-training';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Reference" href="../reference/index.html" />
    <link rel="prev" title="Checking autograd forces against analytical forces for Embedded Atom model" href="eam-forces.html" />
<!-- <link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css"> -->

<script src="https://code.jquery.com/jquery-1.12.4.min.js" type="text/javascript"></script>
<script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>
<script async type="text/javascript" id="_fed_an_ua_tag" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=NIST&subagency=github&pua=UA-66610693-1&yt=true&exts=ppsx,pps,f90,sch,rtf,wrl,txz,m1v,xlsm,msi,xsd,f,tif,eps,mpg,xml,pl,xlt,c">
</script>


<script type="text/javascript" src="https://pages.nist.gov/leaveNotice/js/jquery.leaveNotice-nist.min.js"></script>
<script>
$(document).ready(function(){
  // Mark external (non-nist.gov) A tags with class "external"
  //If the adress start with https and ends with nist.gov
  var re_nist = new RegExp('^https?:\/\/((^\/)*\.)*nist\\.gov(\/|$)');
  //Regex to find address that start with https
  var re_absolute_address = new RegExp('^((https?:)?\/\/)');
  $("a").each(function(){
    var url=$(this).attr('href');
    if(re_nist.test(url) || !re_absolute_address.test(url)){
      $(this).addClass('local');
    }else{
      //This a href appears to be external, so tag it
      $(this).addClass('external');
    }
  });
  // Add leaveNotice to external A elements
  $('a.external').leaveNotice();
});
</script>
<link rel="stylesheet" type="text/css" href="https://pages.nist.gov/leaveNotice/css/jquery.leaveNotice.css" />


  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">nfflr 0.2.1 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/quickstart.html">Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/atoms.html">Atoms</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">How-to guides</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="property-regression.html">Property regression example</a></li>

<li class="toctree-l2"><a class="reference internal" href="eam-forces.html">Checking autograd forces against analytical forces for Embedded Atom model</a></li>

<li class="toctree-l2 current active"><a class="current reference internal" href="#">Force field example</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../reference/index.html">Reference</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../reference/atoms.html">nfflr.Atoms</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.PeriodicRadiusGraph.html">nfflr.nn.PeriodicRadiusGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.PeriodicKShellGraph.html">nfflr.nn.PeriodicKShellGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.PeriodicAdaptiveRadiusGraph.html">nfflr.nn.PeriodicAdaptiveRadiusGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.AtomType.html">nfflr.nn.AtomType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.AtomPairType.html">nfflr.nn.AtomPairType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.AttributeEmbedding.html">nfflr.nn.AttributeEmbedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.AtomicNumberEmbedding.html">nfflr.nn.AtomicNumberEmbedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.PeriodicTableEmbedding.html">nfflr.nn.PeriodicTableEmbedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.batch.html">nfflr.batch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.unbatch.html">nfflr.unbatch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.spglib_cell.html">nfflr.spglib_cell</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.to_ase.html">nfflr.to_ase</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../reference/dataset.html">nfflr.AtomsDataset</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.data.mlearn_dataset.html">nfflr.data.mlearn_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.data.deepmd_hea_dataset.html">nfflr.data.deepmd_hea_dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../reference/nn.html">nfflr.nn</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.RBFExpansion.html">RBFExpansion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.ChebyshevExpansion.html">ChebyshevExpansion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.EdgeGatedGraphConv.html">EdgeGatedGraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.ALIGNNConv.html">ALIGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.SparseALIGNNConv.html">SparseALIGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.XPLOR.html">XPLOR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.FeedForward.html">FeedForward</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.MLPLayer.html">MLPLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.Norm.html">Norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.nn.InstanceNorm.html">InstanceNorm</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../reference/models.html">nfflr.models</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.models.ALIGNN.html">ALIGNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.models.SchNet.html">SchNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/generated/nfflr.models.Tersoff.html">Tersoff</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/usnistgov/nfflr" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/usnistgov/nfflr/issues/new?title=Issue%20on%20page%20%2Fhowto/force-field-training.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Force field example</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Force field example</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#low-level-interface">low level interface</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-ignite-based-nfflr-trainer">using the ignite-based NFFLr trainer</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="force-field-example">
<h1>Force field example<a class="headerlink" href="#force-field-example" title="Link to this heading">#</a></h1>
<section id="low-level-interface">
<h2>low level interface<a class="headerlink" href="#low-level-interface" title="Link to this heading">#</a></h2>
<p>To show how the components of NFFLr work together, let’s train a formation energy model using the <code class="docutils literal notranslate"><span class="pre">mlearn</span></code> dataset.
We can use the <code class="docutils literal notranslate"><span class="pre">periodic_radius_graph</span></code> transform to configure the <code class="docutils literal notranslate"><span class="pre">AtomsDataset</span></code> to automatically transform atomic configurations into <code class="docutils literal notranslate"><span class="pre">DGLGraph</span></code>s.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nfflr</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">nfflr</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">PeriodicRadiusGraph</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">nfflr</span><span class="o">.</span><span class="n">AtomsDataset</span><span class="p">(</span>
    <span class="s2">&quot;mlearn&quot;</span><span class="p">,</span> 
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;energy_and_forces&quot;</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dataset_name=&#39;mlearn&#39;
Obtaining mlearn dataset 1730...
Reference:https://github.com/materialsvirtuallab/mlearn
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0.00/2.57M [00:00&lt;?, ?iB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 8.19k/2.57M [00:00&lt;00:40, 62.7kiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2%|▏         | 60.4k/2.57M [00:00&lt;00:09, 255kiB/s] 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  4%|▍         | 113k/2.57M [00:00&lt;00:07, 336kiB/s] 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10%|█         | 269k/2.57M [00:00&lt;00:03, 672kiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22%|██▏       | 565k/2.57M [00:00&lt;00:01, 1.23MiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45%|████▍     | 1.16M/2.57M [00:00&lt;00:00, 2.31MiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91%|█████████▏| 2.35M/2.57M [00:00&lt;00:00, 4.44MiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 2.57M/2.57M [00:00&lt;00:00, 2.71MiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading the zipfile...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading completed.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(Graph(num_nodes=107, num_edges=11342,
       ndata_schemes={&#39;coord&#39;: Scheme(shape=(3,), dtype=torch.float32), &#39;atomic_number&#39;: Scheme(shape=(), dtype=torch.int32)}
       edata_schemes={&#39;r&#39;: Scheme(shape=(3,), dtype=torch.float32)}),
 {&#39;energy&#39;: tensor(-64656.0625),
  &#39;forces&#39;: tensor([[-1.9282e-01, -1.8793e+00, -6.6374e-01],
          [-8.2543e-03, -2.0313e-01,  3.6808e-01],
          [-5.5372e-01, -1.4736e+00,  1.2997e+00],
          [ 4.5678e-01,  5.1175e-01, -1.0934e+00],
          [-1.6499e+00, -1.6259e+00,  4.5255e-01],
          [-1.6698e-01,  6.8080e-01,  6.7749e-01],
          [ 3.6802e-02, -3.1423e+00, -2.0166e+00],
          [-1.0730e-01, -3.5780e-01,  1.1357e+00],
          [-1.9132e-01,  5.1381e-01,  3.4296e-01],
          [ 2.0090e+00,  1.5143e+00, -3.5578e-01],
          [-1.7128e-01, -2.7808e+00, -1.4215e+00],
          [-9.3987e-01, -1.6757e-02,  7.9322e-01],
          [ 3.7190e-01, -9.0627e-01, -5.2933e-01],
          [ 5.6458e-01, -9.6833e-01, -7.0043e-01],
          [-4.5756e-01, -6.5868e-02, -3.7038e-01],
          [-1.2044e+00,  6.3979e-01,  7.5036e-01],
          [-1.5743e+00,  6.4479e-02, -6.7272e-01],
          [-9.8223e-01, -9.5903e-02, -8.7198e-01],
          [ 4.9518e-01, -2.7982e-01, -4.6208e-01],
          [ 3.3000e-01,  1.7643e-01,  2.0947e+00],
          [ 3.3517e-01,  1.4522e+00,  3.6359e-01],
          [-4.4930e-01, -3.1648e-01,  2.1246e-01],
          [-5.8361e-01,  1.0337e+00, -1.0099e+00],
          [ 1.4334e+00,  1.4563e+00,  4.8775e-01],
          [-1.2193e+00, -1.8368e-01,  1.7678e-01],
          [-1.8822e-02, -3.3724e-01,  5.0373e-01],
          [ 9.7925e-01,  3.4629e-01,  2.7126e-01],
          [ 1.3972e+00,  1.0313e-01,  2.1936e+00],
          [ 1.4154e+00,  1.0657e+00,  5.6893e-01],
          [-5.3909e-01,  6.2667e-01,  7.9585e-01],
          [-8.0468e-02,  9.3723e-01, -1.7657e+00],
          [ 6.4826e-01,  1.3950e-03, -1.1809e+00],
          [ 1.7236e+00,  5.0571e-01,  2.0909e-01],
          [-6.3469e-01,  3.2798e+00,  1.3690e+00],
          [-2.8363e-01,  1.3372e+00, -3.8005e-01],
          [-1.0848e+00, -5.7622e-01, -6.1141e-01],
          [-1.8884e+00,  5.1697e-01, -1.0889e-01],
          [-5.3894e-01,  2.1740e+00,  2.2013e+00],
          [ 1.5727e+00, -9.5217e-01,  9.6934e-01],
          [ 3.8191e-01,  3.4829e-01,  1.2664e+00],
          [-1.1411e+00,  1.2328e+00,  1.2866e+00],
          [ 1.1776e+00,  7.2366e-01, -1.5056e+00],
          [-1.3455e+00, -4.8714e-01,  4.1776e-01],
          [ 2.7808e-01, -1.4488e-01,  1.2792e+00],
          [-2.0664e-01,  1.4243e+00,  1.2686e+00],
          [ 1.3897e+00,  7.7333e-01, -8.4011e-01],
          [-7.0459e-01, -2.1634e+00,  1.0630e+00],
          [-9.9009e-01, -6.2214e-01, -9.4072e-03],
          [ 3.3802e-01,  3.1611e-01,  1.3336e-01],
          [-1.2308e+00, -2.7998e-01, -9.0719e-01],
          [ 1.5169e+00, -6.4886e-01, -1.4431e+00],
          [ 2.3966e+00,  1.3065e+00,  3.9503e-01],
          [ 4.8711e-01,  2.6996e-03,  5.6954e-01],
          [ 3.0038e-02,  9.8048e-01,  9.6736e-02],
          [-2.8896e-01,  6.9839e-01,  1.1865e-01],
          [-7.0303e-01,  1.5889e+00,  1.0517e+00],
          [ 1.4835e+00, -7.5193e-01, -4.8107e-01],
          [ 4.3507e-01, -7.6680e-01, -7.6512e-01],
          [ 1.6324e+00, -9.0497e-01, -1.7391e-01],
          [-7.7163e-01,  8.8480e-01, -1.0546e-01],
          [ 1.5508e+00, -1.4519e-01, -6.3183e-01],
          [ 1.4062e+00,  4.8017e-01,  2.4209e-01],
          [-8.2076e-01, -1.1055e+00, -3.7652e-01],
          [-1.7866e+00, -1.0725e-01, -7.5774e-01],
          [ 6.6219e-01, -1.1061e+00,  6.6820e-01],
          [ 4.5689e-01, -3.1297e-01,  5.2079e-01],
          [-2.3750e-01,  1.6904e+00, -7.2430e-01],
          [ 1.5449e+00,  1.4885e+00, -5.6164e-01],
          [ 1.6403e+00, -1.3929e+00, -1.3473e-01],
          [-5.0026e-01, -7.1965e-01, -6.3690e-01],
          [ 1.8875e-01, -8.0416e-01,  1.0578e+00],
          [ 7.4767e-01, -2.7263e-01,  1.0396e-01],
          [ 1.0797e+00,  6.2834e-01, -1.0441e+00],
          [-9.1592e-01, -1.0053e+00, -1.6651e-01],
          [-2.4538e-01,  1.1315e+00, -2.5051e-01],
          [-2.6349e-01, -3.9915e-01,  5.2209e-01],
          [ 8.3324e-01,  2.9588e-02,  4.1156e-01],
          [ 1.3736e-01,  5.2689e-01, -7.6983e-01],
          [ 1.8699e+00, -5.6415e-01, -1.2089e+00],
          [-8.2056e-01, -5.2394e-01, -1.0657e-01],
          [-1.3969e-01, -2.1350e-01,  2.1012e-01],
          [-8.5827e-01, -2.9145e-01, -8.8987e-02],
          [-2.7861e-01, -6.4112e-01,  2.7514e-01],
          [-7.0377e-01, -1.6119e-01, -1.6974e-02],
          [-4.9227e-01, -5.5502e-01, -1.6419e+00],
          [ 1.3265e+00,  5.1135e-01, -2.0431e-01],
          [-6.3025e-01, -4.0777e-01, -7.4116e-01],
          [-2.7982e+00, -8.6561e-01,  7.2870e-01],
          [ 4.4176e-01, -6.1487e-01, -1.5266e+00],
          [-8.2469e-01, -1.5254e+00,  2.2129e-01],
          [-4.1837e-01,  4.5957e-01, -9.3009e-01],
          [-1.3448e+00, -3.8741e-01,  5.7946e-01],
          [-3.5803e-02, -4.9431e-01, -3.3611e-01],
          [ 1.3890e+00, -2.3396e-01, -5.8913e-01],
          [ 4.6561e-01, -1.6739e+00, -5.8580e-01],
          [-5.4732e-02,  1.2076e+00, -6.2845e-01],
          [-1.9202e+00,  2.6483e-01, -4.7163e-01],
          [ 2.3382e-01, -1.9371e-01,  8.8642e-01],
          [-5.4136e-02,  7.5257e-01, -7.5428e-01],
          [-1.2954e+00, -8.2409e-01, -2.3798e-01],
          [ 2.2413e-01, -5.5878e-02, -5.6709e-01],
          [ 1.0508e+00,  4.7083e-01,  1.0494e+00],
          [ 1.1418e+00,  3.9075e-01,  2.2798e-01],
          [-1.6860e+00,  8.3186e-01,  7.9992e-01],
          [-1.1271e+00,  7.7508e-02,  9.2828e-01],
          [-1.0157e+00,  5.2795e-01, -1.9179e-01],
          [ 4.6428e-01, -1.5829e-01,  7.1079e-01]]),
  &#39;stresses&#39;: tensor([[41.4064,  5.9450, -4.7715],
          [ 5.9450, 41.1876,  1.0425],
          [-4.7715,  1.0425, 51.0653]]),
  &#39;volume&#39;: tensor(1165.6177)})
</pre></div>
</div>
</div>
</div>
<p>Set up a medium-sized ALIGNN model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nfflr.models.gnn</span> <span class="kn">import</span> <span class="n">alignn</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">nfflr</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ALIGNNConfig</span><span class="p">(</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
    <span class="n">cutoff</span><span class="o">=</span><span class="n">nfflr</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">XPLOR</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span>
    <span class="n">alignn_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">gcn_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">embedding_features</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">edge_input_features</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">triplet_input_features</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">hidden_features</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">norm</span><span class="o">=</span><span class="s2">&quot;layernorm&quot;</span><span class="p">,</span> 
    <span class="n">atom_features</span><span class="o">=</span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span>
    <span class="n">compute_forces</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nfflr</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ALIGNN</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>

<span class="n">atoms</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">model</span><span class="p">(</span><span class="n">atoms</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;total_energy&#39;: tensor(-0.0165, grad_fn=&lt;SqueezeBackward0&gt;),
 &#39;forces&#39;: tensor([[ 8.3449e-10,  5.9858e-10,  7.1603e-10],
         [ 6.7397e-09, -5.8617e-09, -1.5252e-10],
         [ 5.6708e-10, -6.6382e-10,  3.2163e-10],
         [-1.6937e-08,  5.2722e-09,  7.5733e-09],
         [ 5.7729e-09,  1.1124e-09, -9.2644e-10],
         [-2.7068e-10, -9.9168e-10,  1.1128e-09],
         [-1.4659e-08,  3.5748e-09, -4.1437e-09],
         [ 9.5788e-09, -2.7910e-10,  2.7007e-09],
         [ 1.1325e-09,  7.3393e-10, -1.4862e-09],
         [ 6.6506e-09, -9.9221e-09,  5.9164e-09],
         [ 3.4962e-09,  8.8358e-09, -1.9326e-09],
         [-3.6781e-10, -1.3506e-09,  3.3935e-09],
         [ 3.8453e-09,  2.5543e-09,  3.8028e-09],
         [-3.1162e-09, -3.8064e-09,  4.7148e-09],
         [ 1.6480e-09, -1.3333e-09, -1.2344e-09],
         [ 7.7030e-09, -7.1531e-09,  8.7229e-09],
         [-7.4225e-10, -2.1737e-11,  2.7527e-09],
         [-1.0964e-09, -4.4794e-09,  4.2397e-09],
         [ 2.8125e-10,  3.4327e-09,  2.7604e-09],
         [-3.9617e-09, -1.3246e-08, -2.4046e-09],
         [-3.3289e-09,  4.9245e-09, -1.2268e-08],
         [ 2.6885e-09, -9.7567e-10,  5.8504e-10],
         [-5.3308e-09,  7.2968e-09, -6.4652e-09],
         [-4.4548e-10, -1.0550e-09, -6.6570e-10],
         [ 3.6677e-09,  3.7982e-10, -1.6810e-09],
         [ 6.9886e-09,  5.6341e-09,  7.1412e-09],
         [-1.3554e-08,  1.0420e-08,  1.1179e-08],
         [-4.6044e-09,  4.4272e-09,  1.2987e-09],
         [-4.0500e-09,  3.3723e-09, -2.2084e-09],
         [-5.8669e-10, -1.3048e-09,  2.4909e-09],
         [ 1.0698e-08, -2.3011e-09,  7.8960e-10],
         [ 1.5859e-09, -1.3160e-09,  6.4721e-10],
         [-2.0524e-09, -2.8328e-09,  3.6832e-09],
         [-1.4015e-08,  7.2798e-09,  4.5109e-10],
         [ 1.0503e-08, -6.2192e-09, -4.8330e-09],
         [-2.5222e-09, -3.5723e-09, -4.1476e-09],
         [ 2.7813e-09,  4.8970e-09,  1.8300e-09],
         [ 7.1739e-11, -5.6536e-10,  1.8381e-09],
         [ 3.0279e-09, -1.6393e-09,  3.4353e-09],
         [ 6.4926e-10, -5.6677e-10,  1.7414e-09],
         [ 3.6366e-09, -9.1498e-11, -3.3292e-09],
         [-3.2370e-09,  6.5965e-09, -1.0364e-08],
         [ 4.1584e-09, -9.5249e-09,  2.3705e-09],
         [ 4.0337e-09, -7.9000e-09, -4.9817e-09],
         [ 2.3755e-09, -2.0342e-09, -1.8757e-09],
         [-1.5097e-09,  8.2876e-09,  1.7788e-09],
         [-1.0534e-09,  5.7153e-09, -4.7889e-09],
         [ 2.7022e-09, -9.0073e-10, -3.9236e-09],
         [-5.7201e-09, -1.0507e-09,  2.4834e-09],
         [-4.4308e-09, -1.3640e-09, -9.1588e-09],
         [-5.1583e-11, -3.8773e-09,  3.0449e-09],
         [-8.6966e-11, -4.5578e-09,  1.0028e-09],
         [-5.1982e-09, -1.2939e-08, -8.9342e-09],
         [ 3.7953e-09, -5.3027e-09,  3.7691e-09],
         [ 5.7416e-09, -8.1641e-09,  1.4570e-09],
         [ 7.3353e-09, -1.0083e-08, -4.6248e-09],
         [ 4.5327e-09,  1.3733e-09,  5.1716e-09],
         [ 1.4192e-09,  1.4791e-10,  8.1085e-10],
         [ 6.6419e-09,  1.9687e-09, -4.0846e-09],
         [-3.9884e-09, -2.8835e-09, -4.2246e-09],
         [ 6.1083e-09, -3.8214e-09,  1.9210e-09],
         [ 1.2280e-09, -7.8299e-10,  1.0533e-09],
         [-7.3770e-10,  1.1873e-08,  8.5370e-09],
         [ 1.6001e-09,  1.9807e-08,  2.7549e-09],
         [ 8.9117e-10, -1.0663e-09,  1.2923e-09],
         [ 2.1278e-09,  1.2072e-09,  4.3073e-09],
         [ 1.7173e-09,  1.4923e-09,  1.1925e-09],
         [ 1.5660e-09,  3.2508e-09, -4.8781e-09],
         [ 1.9846e-09, -1.5249e-09,  2.8118e-09],
         [ 8.6757e-10, -1.4818e-09,  1.5246e-09],
         [ 4.6926e-10, -7.1979e-09, -1.0107e-08],
         [ 5.4005e-09,  7.2238e-09, -4.3526e-09],
         [ 7.6451e-10, -1.2536e-09,  9.3505e-10],
         [-1.7894e-09,  5.3083e-09, -2.0951e-09],
         [-2.3052e-09,  2.2295e-09,  6.2922e-09],
         [-7.7584e-09,  4.8472e-09,  1.7017e-09],
         [-1.9300e-09,  8.5278e-10, -2.9608e-09],
         [-5.2282e-09, -4.0006e-09,  7.6250e-09],
         [-1.0331e-08, -8.5484e-09,  4.4438e-10],
         [-1.0687e-08, -8.0705e-09, -1.1081e-08],
         [-2.5529e-09, -3.9494e-09,  5.1508e-09],
         [ 3.7423e-09,  3.4759e-09,  3.5505e-09],
         [ 5.7290e-09,  4.5371e-09,  5.6513e-10],
         [ 9.3652e-09,  4.6095e-10, -1.0311e-08],
         [-3.6997e-09, -1.1223e-09, -6.8892e-10],
         [-1.0766e-09, -8.3745e-10,  1.3407e-09],
         [-1.5561e-09,  3.6915e-10, -4.2249e-09],
         [-3.4813e-11, -6.1289e-10,  1.6272e-09],
         [-2.1123e-09,  2.1372e-09,  3.9621e-09],
         [ 1.3222e-09,  1.3573e-08,  2.1147e-08],
         [ 6.8015e-10, -3.1515e-11,  8.0037e-10],
         [ 1.5171e-09,  5.0257e-09, -4.2375e-10],
         [ 1.0193e-09, -1.2542e-09, -3.2441e-08],
         [ 1.4569e-09, -7.5779e-10,  4.1569e-10],
         [ 1.3088e-09, -8.0219e-10, -8.6477e-10],
         [ 8.7808e-10,  4.7780e-09, -5.1690e-09],
         [ 1.8838e-09,  6.3691e-09, -3.2930e-09],
         [ 1.2613e-09, -1.0801e-11,  2.4798e-09],
         [-3.4008e-09,  4.8222e-09,  6.5573e-09],
         [-3.6076e-09,  6.2774e-09,  4.6431e-09],
         [-2.5143e-10,  1.8849e-09, -2.5674e-11],
         [-3.3432e-09, -1.1242e-09, -5.2097e-09],
         [-6.2553e-10, -1.0475e-09,  3.0443e-09],
         [-3.2922e-10, -1.6959e-09, -4.1760e-10],
         [-3.8310e-09, -4.4240e-09, -4.9791e-09],
         [-6.4475e-09, -9.0648e-09,  3.6333e-09],
         [-1.6220e-09, -4.0234e-09, -6.7471e-10]], grad_fn=&lt;MulBackward0&gt;),
 &#39;stress&#39;: tensor([[[ 4.4943e-10, -1.4234e-10, -1.1242e-10],
          [-1.4234e-10,  8.9622e-10,  2.7166e-10],
          [-1.1242e-10,  2.7166e-10,  7.4332e-10]]],
        grad_fn=&lt;SegmentReduceBackward&gt;)}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">SubsetRandomSampler</span>

<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> 
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">collate</span><span class="p">,</span> 
    <span class="n">sampler</span><span class="o">=</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]),</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(Graph(num_nodes=118, num_edges=6894,
       ndata_schemes={&#39;coord&#39;: Scheme(shape=(3,), dtype=torch.float32), &#39;atomic_number&#39;: Scheme(shape=(), dtype=torch.int32)}
       edata_schemes={&#39;r&#39;: Scheme(shape=(3,), dtype=torch.float32)}),
 {&#39;total_energy&#39;: tensor([-18194.8398, -30013.3262]),
  &#39;n_atoms&#39;: tensor([64, 54]),
  &#39;forces&#39;: tensor([[ 2.5853e-02,  9.8611e-01,  2.0507e-01],
          [-1.2730e+00,  1.3843e-01, -4.2840e-01],
          [-4.4796e-01,  7.3797e-01, -1.3716e-01],
          [-3.6604e-01,  1.2827e+00,  3.5534e-01],
          [ 9.1047e-03,  1.5494e-01,  1.1547e+00],
          [ 1.1325e+00, -7.0152e-01,  6.8949e-01],
          [ 6.6673e-03,  7.8170e-02,  3.5660e-01],
          [-1.0492e+00,  2.6409e-01,  3.8626e-01],
          [-2.3404e-01, -1.0430e+00, -3.2662e-01],
          [ 1.5453e+00, -8.8978e-01,  7.8531e-01],
          [-2.2359e-01,  1.1316e+00, -2.1501e-01],
          [ 8.0705e-01, -2.2985e-01,  6.6363e-02],
          [ 4.7211e-01, -2.8090e-01, -3.8849e-01],
          [ 1.4042e-01, -1.1338e-01, -3.1061e-01],
          [-5.0200e-01,  4.3822e-01,  8.2500e-01],
          [ 4.7767e-01,  2.2398e-01, -1.0479e+00],
          [ 1.4795e-01,  3.3051e-01,  4.5388e-01],
          [-1.1853e+00,  8.5122e-01, -8.7911e-01],
          [-4.3358e-01, -2.1836e-01,  2.2759e-02],
          [-1.6023e-02, -2.5436e-01,  1.3274e-01],
          [ 1.2482e-01, -6.9267e-01, -3.0560e-01],
          [-5.2384e-01,  4.9275e-01,  5.2799e-02],
          [-1.1121e+00,  5.9261e-01, -3.2202e-01],
          [ 1.3366e-01, -4.5995e-01,  4.0726e-02],
          [-1.0344e+00, -6.5997e-01, -1.2436e+00],
          [ 5.9818e-01,  4.9730e-01, -6.7509e-01],
          [ 8.5395e-01,  4.4162e-01,  1.1549e-01],
          [-1.3433e-01,  4.7631e-01, -1.0361e+00],
          [ 7.8588e-02,  5.7934e-01, -1.1957e+00],
          [ 2.7287e-02, -9.2192e-01, -5.4404e-01],
          [ 5.0987e-01, -8.3838e-01, -4.7795e-02],
          [ 3.2989e-01,  4.3638e-01,  5.8170e-01],
          [ 9.6609e-01,  3.7910e-03,  7.9645e-01],
          [-5.6948e-01, -4.0146e-01,  5.8695e-01],
          [-7.7576e-01,  3.5176e-01, -2.0166e-01],
          [ 2.5146e-01, -3.2403e-01,  8.6999e-01],
          [ 1.6878e-01, -1.9318e-01,  6.7887e-01],
          [ 7.1109e-02, -4.5411e-01, -4.3876e-01],
          [-1.1586e-01, -1.5668e-01, -2.4152e-01],
          [ 7.7751e-02,  1.7442e-03, -1.0016e+00],
          [-1.7049e-01, -5.3221e-01, -3.8009e-01],
          [ 1.9445e-01, -1.9896e-01, -8.0854e-02],
          [ 9.0479e-01,  4.7161e-02,  6.6229e-01],
          [ 1.4917e-01,  2.4673e-01, -9.5883e-01],
          [-7.2418e-02, -3.7183e-01, -3.8055e-02],
          [ 1.6590e-01, -6.1766e-01,  8.2064e-01],
          [-4.4772e-01, -1.1559e+00, -7.4815e-01],
          [-3.3100e-01,  3.8508e-01, -6.0909e-01],
          [-1.5419e-02,  1.3800e+00, -2.5890e-02],
          [-1.4403e-01, -6.0416e-01, -2.5338e-01],
          [-2.6601e-01, -9.5041e-01, -1.4533e-01],
          [-3.6568e-01, -1.6653e-01,  9.1237e-01],
          [-1.5636e-01, -8.0549e-01,  5.7173e-01],
          [-2.8689e-02, -3.0225e-01,  4.4171e-01],
          [ 9.0297e-01,  7.1441e-01,  2.1011e-01],
          [ 5.7502e-01,  2.1273e-01, -6.3153e-01],
          [-9.4646e-01,  3.5421e-02, -5.6549e-01],
          [ 5.7332e-01,  6.0237e-01, -3.7215e-01],
          [ 1.3482e+00, -2.2624e-01, -1.2621e-01],
          [-3.6503e-01,  1.7207e-01, -1.6381e-01],
          [ 6.0741e-01, -3.1627e-01,  1.0157e+00],
          [-4.3873e-01, -5.5769e-01,  5.2282e-01],
          [-1.2852e-01,  5.4163e-01,  8.1759e-01],
          [-5.0430e-01,  8.1004e-01,  9.5422e-01],
          [ 6.6722e-01,  7.8234e-01,  1.0784e+00],
          [-1.6555e+00, -4.2747e-01, -3.1437e+00],
          [-2.2606e-01,  1.3040e+00, -4.1670e-01],
          [ 8.7677e-01, -2.8566e+00,  2.6403e-01],
          [-5.7056e-01, -2.1744e+00, -8.3666e-01],
          [-2.4453e-01, -2.5022e+00,  3.5631e-01],
          [-8.4785e-01,  3.7868e-01, -1.7946e+00],
          [-1.5301e+00,  1.8091e-01,  4.1237e+00],
          [-2.0221e+00, -1.9008e+00, -1.0550e-01],
          [-2.9596e+00, -4.0330e+00, -3.0482e+00],
          [-8.8726e-01,  3.9768e-01, -1.3682e+00],
          [-3.3734e+00,  1.0101e+00,  2.1954e+00],
          [-1.2272e+00,  1.6005e+00, -1.1009e+00],
          [-1.3241e+00,  1.5910e+00, -1.0081e+00],
          [-1.8293e+00, -1.5490e+00, -2.5279e+00],
          [ 1.2134e+00, -4.0464e+00,  1.3175e-02],
          [ 7.5884e-01,  2.2617e+00, -1.6271e+00],
          [ 5.7503e-02,  5.3455e-01,  8.5816e-01],
          [-2.6184e-01,  1.0687e+00,  2.1269e+00],
          [-1.6661e+00,  2.8814e+00, -2.5871e+00],
          [ 2.3911e+00, -9.3149e-01,  9.1532e-01],
          [-4.9535e+00, -4.0810e-01, -3.4510e-02],
          [-3.6735e+00, -5.0501e-01, -9.4786e-03],
          [ 1.0057e+00,  1.8903e-01,  2.0726e+00],
          [-2.6088e-01, -5.8800e-01, -2.4722e+00],
          [-5.5947e-01,  1.2932e+00,  3.0104e+00],
          [-4.4990e+00, -3.7499e+00,  2.3329e+00],
          [-8.4986e-01,  1.4887e+00, -8.0150e-01],
          [-4.6207e-01,  5.4781e-01,  1.1996e+00],
          [ 3.4238e-01,  1.3340e+00, -7.7889e-02],
          [ 6.2354e+00, -2.6803e+00,  6.4496e-01],
          [ 1.7870e+00,  1.0890e+00, -1.0378e+00],
          [ 2.7904e+00, -2.3798e+00,  1.5001e+00],
          [-1.6339e-01,  2.7490e+00,  3.1570e+00],
          [ 4.6869e+00,  2.0155e+00, -1.5891e+00],
          [-3.5985e-01, -6.6705e-01, -5.2270e-02],
          [ 2.7606e+00, -3.5083e-02,  2.6384e+00],
          [ 1.3714e+00,  3.4410e+00, -1.9397e+00],
          [ 9.9033e-01, -6.1043e-01,  3.0942e+00],
          [ 9.3693e-02,  2.0963e+00, -1.2025e+00],
          [-1.9035e+00,  1.5876e+00, -2.1595e+00],
          [ 7.6066e-01,  8.2925e-01,  1.7067e+00],
          [-1.7710e+00, -1.5510e-01, -2.5709e+00],
          [-1.2790e+00, -2.9574e+00, -1.2106e-01],
          [ 1.2768e+00,  1.1058e+00, -3.0022e-01],
          [ 2.6975e+00, -2.4329e+00,  1.7859e+00],
          [ 2.4305e+00, -5.9228e-01,  6.1448e-01],
          [ 7.6749e-01, -2.1487e+00,  2.9803e+00],
          [-3.5843e+00, -1.2962e+00, -1.0666e+00],
          [ 2.9238e+00,  1.9989e+00,  2.9432e+00],
          [-1.5033e+00,  3.7853e+00, -8.2834e-01],
          [ 1.8692e+00,  3.6440e-01, -2.1945e+00],
          [ 4.5567e+00,  9.9333e-01, -1.3064e+00],
          [ 1.1371e+00,  7.2791e-01, -2.2831e+00]]),
  &#39;stresses&#39;: tensor([[[  5.2620,  -3.1823,   2.1518],
           [ -3.1823,   2.4611,   1.7907],
           [  2.1518,   1.7907,   4.1369]],
  
          [[197.4413, -11.4765,   2.1576],
           [-11.4765, 195.4830,  -9.8540],
           [  2.1576,  -9.8540, 216.4447]]])})
</pre></div>
</div>
</div>
</div>
<p>Now we can set up a PyTorch optimizer and objective function and optimize the model parameters with an explicit training loop. See the [PyTorch quickstart tutorial for more context)[https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html].</p>
<p>For force field training, we use a custom loss function since the output of the model is structured:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">criteria</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;total_energy&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="s2">&quot;forces&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">HuberLoss</span><span class="p">(</span><span class="n">delta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)}</span>

<span class="k">def</span> <span class="nf">ff_criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Specify combined energy and force loss.&quot;&quot;&quot;</span>

    <span class="n">n_atoms</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="s2">&quot;n_atoms&quot;</span><span class="p">]</span>

    <span class="c1"># scale loss by crystal size</span>
    <span class="n">energy_loss</span> <span class="o">=</span> <span class="n">criteria</span><span class="p">[</span><span class="s2">&quot;total_energy&quot;</span><span class="p">](</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;total_energy&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_atoms</span><span class="p">,</span> <span class="n">targets</span><span class="p">[</span><span class="s2">&quot;total_energy&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_atoms</span>
    <span class="p">)</span>

    <span class="c1"># # scale the forces before the loss</span>
    <span class="n">force_scale</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">force_loss</span> <span class="o">=</span> <span class="n">criteria</span><span class="p">[</span><span class="s2">&quot;forces&quot;</span><span class="p">](</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;forces&quot;</span><span class="p">],</span> <span class="n">targets</span><span class="p">[</span><span class="s2">&quot;forces&quot;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">energy_loss</span> <span class="o">+</span> <span class="n">force_scale</span> <span class="o">*</span> <span class="n">force_loss</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">training_loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">ff_criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="n">training_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/690 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 1/690 [00:05&lt;1:07:18,  5.86s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 2/690 [00:06&lt;34:09,  2.98s/it]  
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 3/690 [00:07&lt;23:26,  2.05s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 4/690 [00:08&lt;18:40,  1.63s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 5/690 [00:13&lt;30:37,  2.68s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 6/690 [00:14&lt;23:08,  2.03s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 7/690 [00:19&lt;33:55,  2.98s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 8/690 [00:23&lt;40:10,  3.53s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|▏         | 9/690 [00:28&lt;44:12,  3.90s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|▏         | 10/690 [00:29&lt;34:00,  3.00s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|▏         | 10/690 [00:29&lt;33:44,  2.98s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">line</span> <span class="mi">26</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span>     <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)):</span>
<span class="ne">---&gt; </span><span class="mi">26</span>         <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span>         <span class="n">loss</span> <span class="o">=</span> <span class="n">ff_criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span>         <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/plum/function.py:484,</span> in <span class="ni">_BoundFunction.__call__</span><span class="nt">(self, _, *args, **kw_args)</span>
<span class="g g-Whitespace">    </span><span class="mi">483</span> <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw_args</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">484</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_instance</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw_args</span><span class="p">)</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">1</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File ~/work/nfflr/nfflr/nfflr/models/gnn/alignn.py:179,</span> in <span class="ni">ALIGNN.forward</span><span class="nt">(self, g)</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alignn_layers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span>     <span class="k">if</span> <span class="n">lg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">179</span>         <span class="n">lg</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">line_graph</span><span class="p">(</span><span class="n">shared</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">181</span>     <span class="n">lg</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span><span class="n">compute_bond_cosines</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">182</span>     <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">angle_embedding</span><span class="p">(</span><span class="n">lg</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;h&quot;</span><span class="p">))</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/dgl/utils/internal.py:1051,</span> in <span class="ni">alias_func.&lt;locals&gt;._fn</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1049</span> <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1050</span> <span class="k">def</span> <span class="nf">_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1051</span>     <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/dgl/transforms/functional.py:1121,</span> in <span class="ni">line_graph</span><span class="nt">(g, backtracking, shared)</span>
<span class="g g-Whitespace">   </span><span class="mi">1117</span> <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">,</span> <span class="s2">&quot;only homogeneous graph is supported&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1119</span> <span class="n">dev</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
<span class="g g-Whitespace">   </span><span class="mi">1120</span> <span class="n">lg</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">1121</span>     <span class="n">_CAPI_DGLHeteroLineGraph</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">nd</span><span class="o">.</span><span class="n">cpu</span><span class="p">()),</span> <span class="n">backtracking</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1122</span> <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1123</span> <span class="n">lg</span> <span class="o">=</span> <span class="n">lg</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1124</span> <span class="k">if</span> <span class="n">shared</span><span class="p">:</span>

<span class="nn">File dgl/_ffi/_cython/./function.pxi:296,</span> in <span class="ni">dgl._ffi._cy3.core.FunctionBase.__call__</span><span class="nt">()</span>

<span class="nn">File dgl/_ffi/_cython/./function.pxi:172,</span> in <span class="ni">dgl._ffi._cy3.core.make_ret</span><span class="nt">()</span>

<span class="nn">File dgl/_ffi/_cython/./object.pxi:25,</span> in <span class="ni">dgl._ffi._cy3.core.make_ret_object</span><span class="nt">()</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/dgl/heterograph_index.py:27,</span> in <span class="ni">HeteroGraphIndex.__new__</span><span class="nt">(cls)</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span> <span class="nd">@register_object</span><span class="p">(</span><span class="s2">&quot;graph.HeteroGraph&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="k">class</span> <span class="nc">HeteroGraphIndex</span><span class="p">(</span><span class="n">ObjectBase</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span><span class="w">     </span><span class="sd">&quot;&quot;&quot;HeteroGraph index object.</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span><span class="sd"> </span>
<span class="g g-Whitespace">     </span><span class="mi">22</span><span class="sd">     Note</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span><span class="sd">     ----</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span><span class="sd">     Do not create GraphIndex directly.</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">---&gt; </span><span class="mi">27</span>     <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span>         <span class="n">obj</span> <span class="o">=</span> <span class="n">ObjectBase</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">29</span>         <span class="n">obj</span><span class="o">.</span><span class="n">_cache</span> <span class="o">=</span> <span class="p">{}</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="using-the-ignite-based-nfflr-trainer">
<h1>using the ignite-based NFFLr trainer<a class="headerlink" href="#using-the-ignite-based-nfflr-trainer" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">nfflr</span> <span class="kn">import</span> <span class="n">train</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">training_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
    <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span>
    <span class="s2">&quot;criterion&quot;</span><span class="p">:</span> <span class="n">ff_criterion</span><span class="p">,</span>
    <span class="s2">&quot;random_seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;progress&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span><span class="o">.</span><span class="n">name</span>
<span class="p">}</span>
<span class="n">train</span><span class="o">.</span><span class="n">run_train</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">training_config</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-01-24 15:14:13,264 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset &#39;&lt;nfflr.data.dataset.&#39;: 
	{&#39;collate_fn&#39;: &lt;function AtomsDataset.collate_forcefield at 0x2a3b2e4d0&gt;, &#39;batch_size&#39;: 2, &#39;sampler&#39;: &lt;torch.utils.data.sampler.SubsetRandomSampler object at 0x107f29510&gt;, &#39;drop_last&#39;: True, &#39;num_workers&#39;: 0, &#39;pin_memory&#39;: False}
2024-01-24 15:14:13,264 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset &#39;&lt;nfflr.data.dataset.&#39;: 
	{&#39;collate_fn&#39;: &lt;function AtomsDataset.collate_forcefield at 0x2a3b2e4d0&gt;, &#39;batch_size&#39;: 2, &#39;sampler&#39;: &lt;torch.utils.data.sampler.SubsetRandomSampler object at 0x2aadad4b0&gt;, &#39;drop_last&#39;: True, &#39;num_workers&#39;: 0, &#39;pin_memory&#39;: False}
/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>starting training loop
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "cf07c663016546bca429b7ec74f4ad38", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: 
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">17</span><span class="p">],</span> <span class="n">line</span> <span class="mi">17</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">training_config</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>     <span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>     <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span>     <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span><span class="o">.</span><span class="n">name</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="p">}</span>
<span class="ne">---&gt; </span><span class="mi">17</span> <span class="n">train</span><span class="o">.</span><span class="n">run_train</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">training_config</span><span class="p">)</span>

<span class="nn">File ~/projects/nfflr/nfflr/train.py:278,</span> in <span class="ni">run_train</span><span class="nt">(local_rank, config)</span>
<span class="g g-Whitespace">    </span><span class="mi">273</span>         <span class="n">val_evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">274</span>             <span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">engine</span><span class="p">:</span> <span class="n">session</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">275</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">277</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;starting training loop&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">278</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">280</span> <span class="k">return</span> <span class="n">val_evaluator</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:892,</span> in <span class="ni">Engine.run</span><span class="nt">(self, data, max_epochs, epoch_length, seed)</span>
<span class="g g-Whitespace">    </span><span class="mi">889</span>     <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">data</span>
<span class="g g-Whitespace">    </span><span class="mi">891</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">interrupt_resume_enabled</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">892</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_internal_run</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">893</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">894</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_internal_run_legacy</span><span class="p">()</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:935,</span> in <span class="ni">Engine._internal_run</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">933</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_internal_run_generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_internal_run_as_gen</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">934</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">935</span>     <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_run_generator</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">936</span> <span class="k">except</span> <span class="ne">StopIteration</span> <span class="k">as</span> <span class="n">out</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">937</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_internal_run_generator</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:993,</span> in <span class="ni">Engine._internal_run_as_gen</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">991</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_dataloader_iter</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">992</span>     <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Engine run is terminating due to exception: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">993</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_handle_exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">995</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataloader_iter</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">996</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:638,</span> in <span class="ni">Engine._handle_exception</span><span class="nt">(self, e)</span>
<span class="g g-Whitespace">    </span><span class="mi">636</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EXCEPTION_RAISED</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">637</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">638</span>     <span class="k">raise</span> <span class="n">e</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:959,</span> in <span class="ni">Engine._internal_run_as_gen</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">956</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataloader_iter</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">957</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_setup_engine</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">959</span> <span class="n">epoch_time_taken</span> <span class="o">+=</span> <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_once_on_dataset_as_gen</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">961</span> <span class="c1"># time is available for handlers but must be updated after fire</span>
<span class="g g-Whitespace">    </span><span class="mi">962</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_time_taken</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:1068,</span> in <span class="ni">Engine._run_once_on_dataset_as_gen</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1065</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1066</span> <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_terminate_or_interrupt</span><span class="p">()</span>
<span class="ne">-&gt; </span><span class="mi">1068</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1069</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1070</span> <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_terminate_or_interrupt</span><span class="p">()</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/__init__.py:112,</span> in <span class="ni">supervised_training_step.&lt;locals&gt;.update</span><span class="nt">(engine, batch)</span>
<span class="g g-Whitespace">    </span><span class="mi">110</span> <span class="k">if</span> <span class="n">gradient_accumulation_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">111</span>     <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">gradient_accumulation_steps</span>
<span class="ne">--&gt; </span><span class="mi">112</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">if</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span> <span class="o">%</span> <span class="n">gradient_accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">114</span>     <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/_tensor.py:487,</span> in <span class="ni">Tensor.backward</span><span class="nt">(self, gradient, retain_graph, create_graph, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">477</span> <span class="k">if</span> <span class="n">has_torch_function_unary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">478</span>     <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">479</span>         <span class="n">Tensor</span><span class="o">.</span><span class="n">backward</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">480</span>         <span class="p">(</span><span class="bp">self</span><span class="p">,),</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">485</span>         <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">486</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">487</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">488</span>     <span class="bp">self</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span>
<span class="g g-Whitespace">    </span><span class="mi">489</span> <span class="p">)</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/autograd/__init__.py:200,</span> in <span class="ni">backward</span><span class="nt">(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span>     <span class="n">retain_graph</span> <span class="o">=</span> <span class="n">create_graph</span>
<span class="g g-Whitespace">    </span><span class="mi">197</span> <span class="c1"># The reason we repeat same the comment below is that</span>
<span class="g g-Whitespace">    </span><span class="mi">198</span> <span class="c1"># some Python versions print out the first line of a multi-line function</span>
<span class="g g-Whitespace">    </span><span class="mi">199</span> <span class="c1"># calls in the traceback and some print out the last line</span>
<span class="ne">--&gt; </span><span class="mi">200</span> <span class="n">Variable</span><span class="o">.</span><span class="n">_execution_engine</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span>  <span class="c1"># Calls into the C++ engine to run the backward pass</span>
<span class="g g-Whitespace">    </span><span class="mi">201</span>     <span class="n">tensors</span><span class="p">,</span> <span class="n">grad_tensors_</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="n">allow_unreachable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">accumulate_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nn">File ~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/autograd/function.py:264,</span> in <span class="ni">BackwardCFunction.apply</span><span class="nt">(self, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">263</span> <span class="k">class</span> <span class="nc">BackwardCFunction</span><span class="p">(</span><span class="n">_C</span><span class="o">.</span><span class="n">_FunctionBase</span><span class="p">,</span> <span class="n">FunctionCtx</span><span class="p">,</span> <span class="n">_HookMixin</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">264</span>     <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">265</span>         <span class="c1"># _forward_cls is defined by derived class</span>
<span class="g g-Whitespace">    </span><span class="mi">266</span>         <span class="c1"># The user should define either backward or vjp but never both.</span>
<span class="g g-Whitespace">    </span><span class="mi">267</span>         <span class="n">backward_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_cls</span><span class="o">.</span><span class="n">backward</span>  <span class="c1"># type: ignore[attr-defined]</span>
<span class="g g-Whitespace">    </span><span class="mi">268</span>         <span class="n">vjp_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_cls</span><span class="o">.</span><span class="n">vjp</span>  <span class="c1"># type: ignore[attr-defined]</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="eam-forces.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Checking autograd forces against analytical forces for Embedded Atom model</p>
      </div>
    </a>
    <a class="right-next"
       href="../reference/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Reference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Force field example</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#low-level-interface">low level interface</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-ignite-based-nfflr-trainer">using the ignite-based NFFLr trainer</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Brian DeCost
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Brian DeCost.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>