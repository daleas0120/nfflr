{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force field example\n",
    "\n",
    "## low level interface\n",
    "\n",
    "To show how the components of NFFLr work together, let's train a formation energy model using the `mlearn` dataset.\n",
    "We can use the `periodic_radius_graph` transform to configure the `AtomsDataset` to automatically transform atomic configurations into `DGLGraph`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name='mlearn'\n",
      "Obtaining mlearn dataset 1730...\n",
      "Reference:https://github.com/materialsvirtuallab/mlearn\n",
      "Loading the zipfile...\n",
      "Loading completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=107, num_edges=11342,\n",
       "       ndata_schemes={'coord': Scheme(shape=(3,), dtype=torch.float32), 'atomic_number': Scheme(shape=(), dtype=torch.int32)}\n",
       "       edata_schemes={'r': Scheme(shape=(3,), dtype=torch.float32)}),\n",
       " {'energy': tensor(-64656.0625),\n",
       "  'forces': tensor([[-1.9282e-01, -1.8793e+00, -6.6374e-01],\n",
       "          [-8.2543e-03, -2.0313e-01,  3.6808e-01],\n",
       "          [-5.5372e-01, -1.4736e+00,  1.2997e+00],\n",
       "          [ 4.5678e-01,  5.1175e-01, -1.0934e+00],\n",
       "          [-1.6499e+00, -1.6259e+00,  4.5255e-01],\n",
       "          [-1.6698e-01,  6.8080e-01,  6.7749e-01],\n",
       "          [ 3.6802e-02, -3.1423e+00, -2.0166e+00],\n",
       "          [-1.0730e-01, -3.5780e-01,  1.1357e+00],\n",
       "          [-1.9132e-01,  5.1381e-01,  3.4296e-01],\n",
       "          [ 2.0090e+00,  1.5143e+00, -3.5578e-01],\n",
       "          [-1.7128e-01, -2.7808e+00, -1.4215e+00],\n",
       "          [-9.3987e-01, -1.6757e-02,  7.9322e-01],\n",
       "          [ 3.7190e-01, -9.0627e-01, -5.2933e-01],\n",
       "          [ 5.6458e-01, -9.6833e-01, -7.0043e-01],\n",
       "          [-4.5756e-01, -6.5868e-02, -3.7038e-01],\n",
       "          [-1.2044e+00,  6.3979e-01,  7.5036e-01],\n",
       "          [-1.5743e+00,  6.4479e-02, -6.7272e-01],\n",
       "          [-9.8223e-01, -9.5903e-02, -8.7198e-01],\n",
       "          [ 4.9518e-01, -2.7982e-01, -4.6208e-01],\n",
       "          [ 3.3000e-01,  1.7643e-01,  2.0947e+00],\n",
       "          [ 3.3517e-01,  1.4522e+00,  3.6359e-01],\n",
       "          [-4.4930e-01, -3.1648e-01,  2.1246e-01],\n",
       "          [-5.8361e-01,  1.0337e+00, -1.0099e+00],\n",
       "          [ 1.4334e+00,  1.4563e+00,  4.8775e-01],\n",
       "          [-1.2193e+00, -1.8368e-01,  1.7678e-01],\n",
       "          [-1.8822e-02, -3.3724e-01,  5.0373e-01],\n",
       "          [ 9.7925e-01,  3.4629e-01,  2.7126e-01],\n",
       "          [ 1.3972e+00,  1.0313e-01,  2.1936e+00],\n",
       "          [ 1.4154e+00,  1.0657e+00,  5.6893e-01],\n",
       "          [-5.3909e-01,  6.2667e-01,  7.9585e-01],\n",
       "          [-8.0468e-02,  9.3723e-01, -1.7657e+00],\n",
       "          [ 6.4826e-01,  1.3950e-03, -1.1809e+00],\n",
       "          [ 1.7236e+00,  5.0571e-01,  2.0909e-01],\n",
       "          [-6.3469e-01,  3.2798e+00,  1.3690e+00],\n",
       "          [-2.8363e-01,  1.3372e+00, -3.8005e-01],\n",
       "          [-1.0848e+00, -5.7622e-01, -6.1141e-01],\n",
       "          [-1.8884e+00,  5.1697e-01, -1.0889e-01],\n",
       "          [-5.3894e-01,  2.1740e+00,  2.2013e+00],\n",
       "          [ 1.5727e+00, -9.5217e-01,  9.6934e-01],\n",
       "          [ 3.8191e-01,  3.4829e-01,  1.2664e+00],\n",
       "          [-1.1411e+00,  1.2328e+00,  1.2866e+00],\n",
       "          [ 1.1776e+00,  7.2366e-01, -1.5056e+00],\n",
       "          [-1.3455e+00, -4.8714e-01,  4.1776e-01],\n",
       "          [ 2.7808e-01, -1.4488e-01,  1.2792e+00],\n",
       "          [-2.0664e-01,  1.4243e+00,  1.2686e+00],\n",
       "          [ 1.3897e+00,  7.7333e-01, -8.4011e-01],\n",
       "          [-7.0459e-01, -2.1634e+00,  1.0630e+00],\n",
       "          [-9.9009e-01, -6.2214e-01, -9.4072e-03],\n",
       "          [ 3.3802e-01,  3.1611e-01,  1.3336e-01],\n",
       "          [-1.2308e+00, -2.7998e-01, -9.0719e-01],\n",
       "          [ 1.5169e+00, -6.4886e-01, -1.4431e+00],\n",
       "          [ 2.3966e+00,  1.3065e+00,  3.9503e-01],\n",
       "          [ 4.8711e-01,  2.6996e-03,  5.6954e-01],\n",
       "          [ 3.0038e-02,  9.8048e-01,  9.6736e-02],\n",
       "          [-2.8896e-01,  6.9839e-01,  1.1865e-01],\n",
       "          [-7.0303e-01,  1.5889e+00,  1.0517e+00],\n",
       "          [ 1.4835e+00, -7.5193e-01, -4.8107e-01],\n",
       "          [ 4.3507e-01, -7.6680e-01, -7.6512e-01],\n",
       "          [ 1.6324e+00, -9.0497e-01, -1.7391e-01],\n",
       "          [-7.7163e-01,  8.8480e-01, -1.0546e-01],\n",
       "          [ 1.5508e+00, -1.4519e-01, -6.3183e-01],\n",
       "          [ 1.4062e+00,  4.8017e-01,  2.4209e-01],\n",
       "          [-8.2076e-01, -1.1055e+00, -3.7652e-01],\n",
       "          [-1.7866e+00, -1.0725e-01, -7.5774e-01],\n",
       "          [ 6.6219e-01, -1.1061e+00,  6.6820e-01],\n",
       "          [ 4.5689e-01, -3.1297e-01,  5.2079e-01],\n",
       "          [-2.3750e-01,  1.6904e+00, -7.2430e-01],\n",
       "          [ 1.5449e+00,  1.4885e+00, -5.6164e-01],\n",
       "          [ 1.6403e+00, -1.3929e+00, -1.3473e-01],\n",
       "          [-5.0026e-01, -7.1965e-01, -6.3690e-01],\n",
       "          [ 1.8875e-01, -8.0416e-01,  1.0578e+00],\n",
       "          [ 7.4767e-01, -2.7263e-01,  1.0396e-01],\n",
       "          [ 1.0797e+00,  6.2834e-01, -1.0441e+00],\n",
       "          [-9.1592e-01, -1.0053e+00, -1.6651e-01],\n",
       "          [-2.4538e-01,  1.1315e+00, -2.5051e-01],\n",
       "          [-2.6349e-01, -3.9915e-01,  5.2209e-01],\n",
       "          [ 8.3324e-01,  2.9588e-02,  4.1156e-01],\n",
       "          [ 1.3736e-01,  5.2689e-01, -7.6983e-01],\n",
       "          [ 1.8699e+00, -5.6415e-01, -1.2089e+00],\n",
       "          [-8.2056e-01, -5.2394e-01, -1.0657e-01],\n",
       "          [-1.3969e-01, -2.1350e-01,  2.1012e-01],\n",
       "          [-8.5827e-01, -2.9145e-01, -8.8987e-02],\n",
       "          [-2.7861e-01, -6.4112e-01,  2.7514e-01],\n",
       "          [-7.0377e-01, -1.6119e-01, -1.6974e-02],\n",
       "          [-4.9227e-01, -5.5502e-01, -1.6419e+00],\n",
       "          [ 1.3265e+00,  5.1135e-01, -2.0431e-01],\n",
       "          [-6.3025e-01, -4.0777e-01, -7.4116e-01],\n",
       "          [-2.7982e+00, -8.6561e-01,  7.2870e-01],\n",
       "          [ 4.4176e-01, -6.1487e-01, -1.5266e+00],\n",
       "          [-8.2469e-01, -1.5254e+00,  2.2129e-01],\n",
       "          [-4.1837e-01,  4.5957e-01, -9.3009e-01],\n",
       "          [-1.3448e+00, -3.8741e-01,  5.7946e-01],\n",
       "          [-3.5803e-02, -4.9431e-01, -3.3611e-01],\n",
       "          [ 1.3890e+00, -2.3396e-01, -5.8913e-01],\n",
       "          [ 4.6561e-01, -1.6739e+00, -5.8580e-01],\n",
       "          [-5.4732e-02,  1.2076e+00, -6.2845e-01],\n",
       "          [-1.9202e+00,  2.6483e-01, -4.7163e-01],\n",
       "          [ 2.3382e-01, -1.9371e-01,  8.8642e-01],\n",
       "          [-5.4136e-02,  7.5257e-01, -7.5428e-01],\n",
       "          [-1.2954e+00, -8.2409e-01, -2.3798e-01],\n",
       "          [ 2.2413e-01, -5.5878e-02, -5.6709e-01],\n",
       "          [ 1.0508e+00,  4.7083e-01,  1.0494e+00],\n",
       "          [ 1.1418e+00,  3.9075e-01,  2.2798e-01],\n",
       "          [-1.6860e+00,  8.3186e-01,  7.9992e-01],\n",
       "          [-1.1271e+00,  7.7508e-02,  9.2828e-01],\n",
       "          [-1.0157e+00,  5.2795e-01, -1.9179e-01],\n",
       "          [ 4.6428e-01, -1.5829e-01,  7.1079e-01]]),\n",
       "  'stresses': tensor([[41.4064,  5.9450, -4.7715],\n",
       "          [ 5.9450, 41.1876,  1.0425],\n",
       "          [-4.7715,  1.0425, 51.0653]]),\n",
       "  'volume': tensor(1165.6177)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nfflr\n",
    "\n",
    "transform = nfflr.nn.PeriodicRadiusGraph(cutoff=5.0)\n",
    "\n",
    "dataset = nfflr.AtomsDataset(\n",
    "    \"mlearn\", \n",
    "    target=\"energy_and_forces\", \n",
    "    transform=transform,\n",
    ")\n",
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a medium-sized ALIGNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_energy': tensor(0.5054, grad_fn=<SqueezeBackward0>),\n",
       " 'forces': tensor([[-1.9327e-08, -2.0827e-08, -8.1269e-09],\n",
       "         [ 4.9051e-09, -5.9333e-09, -1.5369e-09],\n",
       "         [ 6.6050e-09,  2.4065e-09, -6.7521e-09],\n",
       "         [-8.3214e-09,  2.7671e-09,  3.6863e-10],\n",
       "         [ 7.0100e-09,  1.4210e-09, -2.9856e-09],\n",
       "         [-1.0840e-08, -5.3169e-09,  1.0745e-08],\n",
       "         [-1.7739e-09,  3.0995e-10, -5.1546e-10],\n",
       "         [ 3.0281e-08,  8.8250e-09,  6.9771e-09],\n",
       "         [-6.3300e-09,  1.7157e-08, -2.0408e-08],\n",
       "         [-1.0554e-08,  2.5152e-08, -1.1257e-08],\n",
       "         [ 4.7125e-10, -1.4849e-09, -4.9611e-10],\n",
       "         [-1.2017e-10, -1.6895e-09, -6.7966e-10],\n",
       "         [ 7.0346e-10, -2.4877e-09, -1.4374e-09],\n",
       "         [-5.4707e-09, -7.9745e-09,  3.6146e-09],\n",
       "         [-1.2301e-08,  9.5225e-09,  3.1206e-08],\n",
       "         [ 1.9118e-09, -2.1600e-09, -2.0075e-09],\n",
       "         [ 1.0441e-08, -1.1281e-08, -1.0463e-08],\n",
       "         [-6.2744e-09, -2.1852e-08,  1.9808e-08],\n",
       "         [ 6.9088e-10, -1.8293e-09, -1.3705e-09],\n",
       "         [-1.9137e-09, -7.7778e-09, -4.1829e-09],\n",
       "         [ 6.3732e-09, -8.6592e-09,  1.6584e-08],\n",
       "         [ 1.4425e-09, -2.0753e-10, -1.1843e-09],\n",
       "         [ 3.3277e-09, -5.1168e-09,  1.8290e-09],\n",
       "         [ 6.8021e-09,  3.9980e-09,  2.0574e-08],\n",
       "         [ 1.2181e-08,  7.8364e-09, -1.4762e-08],\n",
       "         [ 7.8816e-09,  5.5763e-09,  4.5595e-09],\n",
       "         [ 1.1206e-09, -2.2336e-10, -2.0918e-09],\n",
       "         [ 4.6102e-09, -3.0464e-09, -1.7289e-09],\n",
       "         [-1.3365e-09, -5.6218e-10, -1.9176e-09],\n",
       "         [ 3.1717e-08, -2.0752e-09, -2.5754e-08],\n",
       "         [ 5.3505e-09, -2.1165e-09, -2.9378e-09],\n",
       "         [-3.7373e-08, -1.9891e-09, -2.8137e-08],\n",
       "         [-1.0775e-09, -3.4055e-09, -1.5357e-09],\n",
       "         [-1.6418e-08,  9.5458e-09, -5.6944e-10],\n",
       "         [-1.0790e-08,  5.6410e-09,  5.8792e-09],\n",
       "         [-3.8704e-09, -1.3912e-08, -1.2897e-08],\n",
       "         [-1.2274e-08, -3.1022e-08, -2.5493e-09],\n",
       "         [-3.6035e-09, -8.9022e-09,  5.9461e-09],\n",
       "         [ 3.1291e-10, -2.1589e-09, -4.6040e-09],\n",
       "         [ 2.2795e-10, -1.6235e-09, -1.2057e-09],\n",
       "         [-1.2555e-08, -3.5289e-09,  2.2383e-08],\n",
       "         [ 2.8265e-09, -3.8148e-09,  1.0000e-09],\n",
       "         [-5.8167e-09,  1.1555e-08, -2.3253e-09],\n",
       "         [-5.3714e-10, -1.8951e-09, -1.7249e-09],\n",
       "         [ 2.0334e-09,  3.5848e-09,  4.0591e-09],\n",
       "         [-4.9894e-09,  1.1124e-08, -4.7728e-10],\n",
       "         [-1.0314e-08,  1.9253e-08, -2.0494e-08],\n",
       "         [ 5.9424e-09, -9.4629e-10, -7.5678e-09],\n",
       "         [ 3.5536e-09, -8.5792e-10, -2.9113e-09],\n",
       "         [-3.9933e-10, -2.6311e-09, -2.0528e-09],\n",
       "         [-3.8907e-09, -1.4955e-08,  1.0822e-08],\n",
       "         [ 1.3099e-08,  2.4329e-08, -3.3231e-09],\n",
       "         [ 9.4996e-09,  1.7111e-08,  1.6744e-08],\n",
       "         [-2.9959e-09,  3.1528e-09, -3.4651e-09],\n",
       "         [-7.8925e-09,  9.9760e-09, -3.6457e-10],\n",
       "         [ 1.4296e-08, -2.4156e-08, -1.5975e-08],\n",
       "         [-2.0938e-08, -1.1444e-08, -2.1279e-08],\n",
       "         [ 2.2192e-09, -9.3466e-10, -1.0034e-10],\n",
       "         [-8.9719e-09, -5.5818e-09,  6.7332e-09],\n",
       "         [-1.5546e-08,  6.6504e-09, -1.7294e-08],\n",
       "         [-1.2743e-09,  1.5878e-10,  1.6175e-10],\n",
       "         [-3.5454e-08,  1.2696e-08,  2.9287e-08],\n",
       "         [-2.8533e-10, -8.3730e-09, -7.6216e-09],\n",
       "         [ 6.6873e-10,  4.8575e-10, -1.0717e-09],\n",
       "         [ 3.0885e-10, -8.5965e-09,  3.8093e-09],\n",
       "         [ 3.5966e-09,  9.0806e-09,  1.7237e-08],\n",
       "         [ 1.5298e-09,  3.3858e-09, -1.9287e-10],\n",
       "         [ 1.7104e-09,  7.1845e-09, -1.5416e-08],\n",
       "         [-3.0976e-10,  1.2326e-08, -3.1484e-08],\n",
       "         [ 3.3928e-10,  8.3104e-09, -2.3619e-09],\n",
       "         [ 1.2455e-09, -6.3573e-09, -9.2228e-09],\n",
       "         [ 3.6315e-09,  1.3251e-09, -3.1283e-09],\n",
       "         [ 2.4565e-08,  3.2789e-08, -3.7792e-09],\n",
       "         [ 1.1801e-08, -1.9700e-08,  1.0520e-08],\n",
       "         [-3.8961e-09,  2.8273e-09,  4.9855e-09],\n",
       "         [ 1.2092e-08, -7.6615e-09, -2.9327e-09],\n",
       "         [ 4.6226e-09, -3.4593e-09,  3.2903e-09],\n",
       "         [-2.2706e-08, -1.3200e-08,  2.3497e-08],\n",
       "         [-1.1409e-09, -3.1961e-09, -2.9211e-09],\n",
       "         [ 1.0684e-08,  3.8876e-09,  8.6804e-09],\n",
       "         [ 5.8728e-09,  4.9035e-09, -8.5885e-09],\n",
       "         [ 5.4078e-09,  2.5736e-09,  1.9016e-09],\n",
       "         [-1.4292e-08, -1.5967e-08,  4.9104e-09],\n",
       "         [-6.1866e-09, -1.0830e-09,  6.0098e-09],\n",
       "         [-6.5492e-09, -1.7396e-09, -3.9176e-09],\n",
       "         [-2.0111e-08, -2.0036e-09,  9.2758e-09],\n",
       "         [ 1.1377e-08, -1.0441e-08,  1.4554e-08],\n",
       "         [ 7.0717e-09, -7.2094e-09,  2.9581e-09],\n",
       "         [-7.4457e-09,  4.3547e-09,  2.1500e-09],\n",
       "         [ 2.9321e-09,  1.5632e-08,  2.1823e-08],\n",
       "         [ 1.0492e-09, -1.3305e-08, -7.7975e-09],\n",
       "         [ 1.3075e-09, -2.3686e-08,  8.8615e-09],\n",
       "         [-2.6595e-11, -1.5207e-09,  9.5095e-10],\n",
       "         [ 1.9428e-09, -1.0206e-09, -2.3427e-09],\n",
       "         [ 1.4002e-09, -2.6741e-09, -9.3615e-09],\n",
       "         [ 3.7009e-10,  2.0913e-08, -3.4893e-08],\n",
       "         [ 1.3466e-09,  2.0721e-08, -1.5314e-08],\n",
       "         [ 2.6479e-11,  2.5767e-08,  1.0222e-08],\n",
       "         [-1.3045e-08,  1.6989e-08,  2.1975e-08],\n",
       "         [ 5.7510e-09, -5.2137e-09, -4.5773e-09],\n",
       "         [ 3.5954e-09, -5.0870e-09,  1.5726e-10],\n",
       "         [ 1.8354e-08, -2.4182e-09,  2.6115e-08],\n",
       "         [ 2.0120e-08, -1.5491e-09, -1.4104e-08],\n",
       "         [ 2.3965e-08, -2.4130e-09,  8.5208e-09],\n",
       "         [ 2.1278e-08,  1.8702e-08,  2.7572e-08],\n",
       "         [-6.5054e-09, -1.0433e-08, -1.9684e-10],\n",
       "         [-3.7569e-09, -7.2208e-09, -4.5846e-09]], grad_fn=<MulBackward0>),\n",
       " 'stress': tensor([[[-1.0268e-09, -1.7002e-10, -2.2171e-10],\n",
       "          [-1.7002e-10, -9.6389e-10,  6.7793e-11],\n",
       "          [-2.2171e-10,  6.7793e-11, -8.2606e-10]]],\n",
       "        grad_fn=<SegmentReduceBackward>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nfflr.models.gnn import alignn\n",
    "\n",
    "cfg = nfflr.models.ALIGNNConfig(\n",
    "    transform=transform,\n",
    "    cutoff=nfflr.nn.XPLOR(4.5, 5.0),\n",
    "    alignn_layers=1, \n",
    "    gcn_layers=2, \n",
    "    embedding_features=16,\n",
    "    edge_input_features=16,\n",
    "    triplet_input_features=16,\n",
    "    hidden_features=32,\n",
    "    norm=\"layernorm\", \n",
    "    atom_features=\"embedding\",\n",
    "    compute_forces=True,\n",
    ")\n",
    "model = nfflr.models.ALIGNN(cfg)\n",
    "\n",
    "atoms, target = dataset[0]\n",
    "model(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=162, num_edges=14418,\n",
       "       ndata_schemes={'coord': Scheme(shape=(3,), dtype=torch.float32), 'atomic_number': Scheme(shape=(), dtype=torch.int32)}\n",
       "       edata_schemes={'r': Scheme(shape=(3,), dtype=torch.float32)}),\n",
       " {'total_energy': tensor([-66990.6328, -31633.8477]),\n",
       "  'n_atoms': tensor([108,  54]),\n",
       "  'forces': tensor([[ 7.4976e-01,  5.2112e-02, -4.4867e-01],\n",
       "          [ 9.8866e-01,  1.5451e-01, -1.3315e+00],\n",
       "          [-1.0298e-02,  6.0375e-02, -1.7932e-02],\n",
       "          [-1.1754e+00, -5.7771e-01,  2.6522e-01],\n",
       "          [-3.7542e-01,  1.9282e-01, -1.1827e-02],\n",
       "          [ 6.3840e-01, -4.9131e-01, -2.1017e-01],\n",
       "          [-2.5444e-01, -1.5675e-01, -1.9500e-02],\n",
       "          [-6.2646e-02, -2.7115e-01,  3.8057e-01],\n",
       "          [-6.9415e-02, -6.5498e-01,  6.0193e-01],\n",
       "          [-5.1347e-01, -5.5116e-01, -1.1137e-01],\n",
       "          [-2.1793e-01, -6.4830e-02,  4.3753e-02],\n",
       "          [-3.7676e-02,  7.0439e-01, -5.6492e-01],\n",
       "          [-9.4828e-01,  8.3889e-02, -5.9573e-01],\n",
       "          [ 2.6064e-01,  2.8835e-01, -8.0409e-02],\n",
       "          [ 9.6534e-03, -3.1432e-01, -3.0291e-01],\n",
       "          [-1.4942e-01, -1.4890e-01,  2.5952e-01],\n",
       "          [-7.3973e-03, -1.0897e-01,  6.9115e-01],\n",
       "          [ 2.3062e-01,  2.6693e-01,  3.3087e-01],\n",
       "          [-1.2886e-01,  4.7388e-01,  5.9554e-03],\n",
       "          [-1.8980e-01,  6.3565e-01, -3.8140e-01],\n",
       "          [ 5.1443e-01, -8.6564e-02,  4.7779e-01],\n",
       "          [ 8.0828e-02, -7.2105e-01,  2.6221e-01],\n",
       "          [ 2.7194e-01, -6.7212e-02,  1.0449e+00],\n",
       "          [ 2.1387e-02, -2.4922e-01, -8.4489e-01],\n",
       "          [-1.9406e-01, -2.0412e-01, -4.0577e-01],\n",
       "          [ 3.5062e-01, -9.0880e-01,  7.2415e-01],\n",
       "          [ 1.2278e-01,  1.6236e-01, -2.6584e-01],\n",
       "          [ 4.9603e-01,  1.5491e-01, -3.1502e-01],\n",
       "          [-5.0265e-01,  3.5055e-01, -4.5375e-03],\n",
       "          [-5.7070e-01, -5.8181e-01, -2.7288e-02],\n",
       "          [ 8.5181e-02, -8.8760e-02,  1.0376e-01],\n",
       "          [ 3.9976e-01,  3.5855e-01, -3.9556e-01],\n",
       "          [ 1.5968e-01, -3.6596e-01, -1.4853e-01],\n",
       "          [-1.4428e-01,  8.3292e-01, -7.0489e-02],\n",
       "          [-1.5209e-01,  2.3471e-01,  6.9172e-01],\n",
       "          [ 1.1556e-01,  1.5758e-01, -3.9324e-01],\n",
       "          [ 3.5278e-01,  2.9662e-01,  4.9260e-01],\n",
       "          [-9.3133e-01, -1.1337e-01,  5.4632e-01],\n",
       "          [-6.2370e-01,  6.5508e-01, -3.0564e-01],\n",
       "          [-1.1853e-01,  3.8254e-02, -6.5960e-01],\n",
       "          [ 1.0355e-01, -3.6278e-01, -6.0311e-02],\n",
       "          [-5.7171e-01,  4.8149e-01,  6.5920e-01],\n",
       "          [-1.6447e-01, -9.7798e-02, -1.8599e-02],\n",
       "          [ 4.1069e-01,  5.7493e-01,  1.5043e-02],\n",
       "          [ 5.7348e-01,  2.5179e-01, -4.4255e-01],\n",
       "          [-1.7758e-02, -2.0493e-01,  2.1370e-02],\n",
       "          [-3.2596e-01, -2.1415e-01, -2.4021e-01],\n",
       "          [-3.6708e-01, -6.6961e-01, -2.2856e-01],\n",
       "          [-7.5554e-02, -4.2251e-02,  3.6461e-01],\n",
       "          [ 1.3775e-01,  3.1889e-01, -2.1676e-01],\n",
       "          [-1.4440e-01, -5.3319e-02,  7.2178e-01],\n",
       "          [-8.0228e-02,  5.0606e-02, -3.9855e-01],\n",
       "          [-3.4361e-01, -1.0185e+00,  5.1657e-01],\n",
       "          [-2.4582e-01,  1.1048e-01, -6.8928e-01],\n",
       "          [-5.0235e-01, -3.4660e-01,  3.2940e-01],\n",
       "          [-2.8076e-01, -6.0953e-01, -3.6390e-01],\n",
       "          [ 6.8814e-02, -2.5110e-01,  7.9535e-01],\n",
       "          [ 1.0824e-01,  1.8466e-01,  6.2404e-01],\n",
       "          [-6.5733e-01, -2.8773e-01, -1.2535e-01],\n",
       "          [ 7.5229e-02,  7.2851e-01,  8.2606e-01],\n",
       "          [-1.9653e-01,  8.6930e-02, -3.4175e-01],\n",
       "          [ 3.9583e-01,  1.9495e-01,  4.8642e-01],\n",
       "          [-6.6979e-01, -6.0029e-03, -8.8857e-02],\n",
       "          [-9.1942e-01,  3.6376e-01,  3.6807e-01],\n",
       "          [ 8.9251e-02, -2.7948e-01,  7.9240e-01],\n",
       "          [ 6.6968e-02, -6.2638e-02, -5.1243e-01],\n",
       "          [ 1.3499e+00, -9.1822e-01, -1.3075e+00],\n",
       "          [-1.6184e-01, -4.1132e-01, -4.3233e-01],\n",
       "          [ 8.2314e-01, -9.7279e-03, -3.3978e-01],\n",
       "          [-1.5463e-01, -3.8616e-01,  3.3117e-02],\n",
       "          [ 1.1079e+00, -1.6139e-01, -4.4824e-02],\n",
       "          [-1.7552e-01, -4.4070e-01,  1.0975e+00],\n",
       "          [ 3.2745e-01, -6.1504e-02,  5.8194e-01],\n",
       "          [-1.6075e-01,  1.0535e-01, -6.6446e-01],\n",
       "          [ 4.5184e-01, -3.6244e-01, -2.6003e-01],\n",
       "          [ 2.8046e-01,  1.5319e-01, -5.1829e-02],\n",
       "          [ 4.1861e-01,  4.2193e-01,  1.8414e-01],\n",
       "          [-3.6426e-01,  3.0024e-01,  4.2195e-01],\n",
       "          [-5.5499e-01,  7.6925e-01,  2.6322e-01],\n",
       "          [-7.6584e-01,  4.0123e-01,  2.8610e-02],\n",
       "          [ 1.0816e+00, -7.7071e-01, -5.4288e-01],\n",
       "          [-1.9699e-01,  2.8061e-01, -4.1939e-01],\n",
       "          [ 3.9883e-01, -1.5821e-01, -3.7869e-01],\n",
       "          [ 7.0299e-01, -2.0586e-01,  6.4937e-01],\n",
       "          [ 1.4721e-01,  2.8078e-01,  6.8565e-01],\n",
       "          [-2.6731e-01,  1.9459e-01,  1.9911e-01],\n",
       "          [ 3.3029e-01, -1.9845e-02, -3.5492e-02],\n",
       "          [-5.3107e-01, -4.6730e-01, -2.7700e-01],\n",
       "          [-4.5629e-01,  2.3998e-01, -1.7029e-01],\n",
       "          [ 9.7514e-02,  4.0428e-01,  1.1032e-01],\n",
       "          [ 5.7307e-01, -2.3678e-01, -1.8612e-01],\n",
       "          [ 4.0084e-02,  9.3262e-02, -5.3326e-01],\n",
       "          [-4.5797e-01, -7.2473e-01, -5.4924e-01],\n",
       "          [-6.4497e-01, -2.8560e-01, -2.8057e-01],\n",
       "          [-3.4726e-01, -1.9792e-02,  1.3043e-01],\n",
       "          [ 4.3120e-01,  7.8279e-01,  7.6162e-02],\n",
       "          [ 3.7620e-01,  9.5747e-01,  6.0733e-02],\n",
       "          [ 1.9683e-02, -1.4492e-01,  4.4298e-01],\n",
       "          [ 1.0420e+00,  2.1808e-01, -6.8948e-01],\n",
       "          [ 6.5260e-01,  7.2283e-01, -2.1927e-01],\n",
       "          [ 1.0653e-01,  1.6843e-01,  4.0224e-01],\n",
       "          [-4.3260e-01,  6.8688e-01,  9.2179e-01],\n",
       "          [ 3.0221e-01,  6.1841e-03, -5.3041e-01],\n",
       "          [-3.3543e-01, -8.0175e-01, -3.0229e-02],\n",
       "          [ 7.4470e-01,  1.1803e-01,  4.1262e-01],\n",
       "          [-4.0638e-01, -3.1976e-02,  4.8390e-02],\n",
       "          [-2.2385e-01,  1.1251e+00, -2.2612e-01],\n",
       "          [-1.0602e-01, -7.9563e-02, -3.8387e-01],\n",
       "          [ 1.2283e-01, -1.6966e-01,  1.4316e-01],\n",
       "          [-7.9404e-02, -1.7067e-01,  1.0365e-01],\n",
       "          [-4.4517e-02, -2.3160e-02, -3.6247e-01],\n",
       "          [ 1.4562e-01, -7.8006e-02,  2.2100e-02],\n",
       "          [ 2.6017e-02,  2.7634e-01, -1.0937e-01],\n",
       "          [-4.1995e-02, -5.8486e-02, -5.1030e-02],\n",
       "          [ 4.3953e-02,  2.0130e-01,  1.0367e-01],\n",
       "          [ 8.0575e-02, -2.3870e-01, -6.8210e-02],\n",
       "          [ 8.1558e-02,  1.0666e-02, -4.4835e-04],\n",
       "          [-9.9154e-02, -1.1480e-01, -8.6046e-03],\n",
       "          [ 2.5776e-01, -1.0497e-01,  1.2380e-02],\n",
       "          [-4.8610e-02, -7.4884e-02, -1.3096e-01],\n",
       "          [ 1.1760e-01,  1.0154e-01,  2.3808e-02],\n",
       "          [-6.0445e-02,  9.0145e-02, -1.8912e-02],\n",
       "          [ 1.8198e-02,  7.7047e-02, -3.2378e-02],\n",
       "          [-2.5841e-01,  6.0065e-02,  6.8258e-02],\n",
       "          [-7.2898e-02,  1.7747e-01,  1.7773e-01],\n",
       "          [ 6.3063e-02, -3.3664e-02, -1.7938e-02],\n",
       "          [ 6.7941e-03,  9.2846e-02, -9.7460e-02],\n",
       "          [-1.8045e-01, -2.2890e-01,  2.3422e-01],\n",
       "          [ 1.5209e-01, -9.1261e-02, -1.7922e-01],\n",
       "          [-7.5514e-02,  3.1873e-02,  2.2366e-01],\n",
       "          [ 8.5040e-02,  1.0900e-01, -1.2532e-02],\n",
       "          [-2.1225e-01, -2.1794e-01, -1.0275e-01],\n",
       "          [ 9.8966e-02, -1.0370e-01, -2.0676e-01],\n",
       "          [-1.2244e-01,  6.8041e-02, -7.3327e-03],\n",
       "          [-3.8415e-02,  4.1390e-01,  2.4585e-01],\n",
       "          [-2.1681e-01,  9.6738e-03,  1.4262e-02],\n",
       "          [-4.3127e-02, -1.4673e-01,  8.2631e-02],\n",
       "          [-1.0499e-01,  1.5257e-01,  1.2558e-01],\n",
       "          [ 8.6501e-03,  4.7264e-02,  1.7938e-04],\n",
       "          [-8.0938e-02,  1.2724e-01, -1.0849e-02],\n",
       "          [ 3.0362e-01, -1.2632e-02, -1.6471e-02],\n",
       "          [-6.9187e-02,  3.1609e-02, -4.5937e-02],\n",
       "          [-9.6464e-02,  6.7954e-02,  8.0190e-02],\n",
       "          [ 7.7760e-02, -1.7007e-01,  8.0849e-02],\n",
       "          [ 1.0289e-01,  6.7307e-03, -2.8638e-01],\n",
       "          [-3.5406e-02,  1.1437e-01, -9.8491e-03],\n",
       "          [-7.2986e-02,  3.3754e-02,  1.7988e-01],\n",
       "          [-3.5138e-03, -3.2854e-01,  1.1252e-01],\n",
       "          [ 5.6453e-02, -7.7088e-02, -9.8600e-02],\n",
       "          [ 4.5680e-02, -1.6750e-01, -3.3692e-02],\n",
       "          [ 1.5402e-01,  1.1733e-01,  1.3244e-02],\n",
       "          [ 1.4485e-01,  3.0871e-02,  3.9841e-02],\n",
       "          [ 1.3152e-01,  4.7976e-02, -2.2218e-01],\n",
       "          [ 6.7524e-02,  2.5682e-01, -7.8385e-02],\n",
       "          [ 1.1487e-01,  7.7417e-02,  3.2245e-01],\n",
       "          [-7.9387e-02, -5.5012e-02, -9.2982e-02],\n",
       "          [-6.3752e-02, -1.6259e-02, -4.2049e-03],\n",
       "          [-5.1313e-02, -2.4788e-01, -1.4986e-01],\n",
       "          [-4.1686e-02,  8.3308e-02,  1.1475e-01],\n",
       "          [ 6.2948e-02, -1.5132e-01, -8.5001e-02],\n",
       "          [ 2.0253e-03,  2.1446e-01, -7.4881e-02],\n",
       "          [-2.7881e-01, -4.7782e-02,  9.0793e-02]]),\n",
       "  'stresses': tensor([[[-16.1608,   0.1737,  -1.5894],\n",
       "           [  0.1737, -13.6996,   0.4766],\n",
       "           [ -1.5894,   0.4766, -10.9025]],\n",
       "  \n",
       "          [[  3.8968,  21.9440,   0.2982],\n",
       "           [ 21.9440,   4.5271,  -0.3142],\n",
       "           [  0.2982,  -0.3142,   3.7983]]])})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "batchsize = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batchsize, \n",
    "    collate_fn=dataset.collate, \n",
    "    sampler=SubsetRandomSampler(dataset.split[\"train\"]),\n",
    "    drop_last=True\n",
    ")\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up a PyTorch optimizer and objective function and optimize the model parameters with an explicit training loop. See the [PyTorch quickstart tutorial for more context)[https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html].\n",
    "\n",
    "For force field training, we use a custom loss function since the output of the model is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/690 [00:00<?, ?it/s]/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "  3%|▎         | 19/690 [00:37<22:18,  1.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, (g, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[0;32m---> 26\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         loss \u001b[38;5;241m=\u001b[39m ff_criterion(pred, y)\n\u001b[1;32m     28\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/plum/function.py:419\u001b[0m, in \u001b[0;36m_BoundFunction.__call__\u001b[0;34m(self, _, *args, **kw_args)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, _, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/plum/function.py:352\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# Cache miss. Run the resolver based on the arguments.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     method, return_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_method(args, types)\n\u001b[0;32m--> 352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m, return_type)\n",
      "File \u001b[0;32m~/projects/nfflr/nfflr/models/gnn/alignn.py:186\u001b[0m, in \u001b[0;36mALIGNN.forward\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# ALIGNN updates: update node, edge, triplet features\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alignn_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malignn_layers:\n\u001b[0;32m--> 186\u001b[0m     x, y, z \u001b[38;5;241m=\u001b[39m \u001b[43malignn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gated GCN updates: update node, edge features\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gcn_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn_layers:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nfflr/nfflr/nn/layers/alignn.py:46\u001b[0m, in \u001b[0;36mALIGNNConv.forward\u001b[0;34m(self, g, lg, x, y, z)\u001b[0m\n\u001b[1;32m     43\u001b[0m x, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_update(g, x, y)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Edge-gated graph convolution update on crystal graph\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m y, z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y, z\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nfflr/nfflr/nn/layers/conv.py:88\u001b[0m, in \u001b[0;36mEdgeGatedGraphConv.forward\u001b[0;34m(self, g, node_feats, edge_feats)\u001b[0m\n\u001b[1;32m     86\u001b[0m     g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(m) \u001b[38;5;241m*\u001b[39m cutoff_value\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBh\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdst_update(node_feats)\n\u001b[1;32m     91\u001b[0m g\u001b[38;5;241m.\u001b[39mupdate_all(fn\u001b[38;5;241m.\u001b[39mu_mul_e(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m), fn\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum_sigma_h\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "criteria = {\"total_energy\": nn.MSELoss(), \"forces\": nn.HuberLoss(delta=0.1)}\n",
    "\n",
    "def ff_criterion(outputs, targets):\n",
    "    \"\"\"Specify combined energy and force loss.\"\"\"\n",
    "\n",
    "    n_atoms = targets[\"n_atoms\"]\n",
    "\n",
    "    # scale loss by crystal size\n",
    "    energy_loss = criteria[\"total_energy\"](\n",
    "        outputs[\"total_energy\"] / n_atoms, targets[\"total_energy\"] / n_atoms\n",
    "    )\n",
    "\n",
    "    # # scale the forces before the loss\n",
    "    force_scale = 1.0\n",
    "    force_loss = criteria[\"forces\"](outputs[\"forces\"], targets[\"forces\"])\n",
    "\n",
    "    return energy_loss + force_scale * force_loss\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "\n",
    "training_loss = []\n",
    "for epoch in range(5):\n",
    "    for step, (g, y) in enumerate(tqdm(train_loader)):\n",
    "        pred = model(g)\n",
    "        loss = ff_criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        training_loss.append(loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the ignite-based NFFLr trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from nfflr import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 15:14:13,264 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset '<nfflr.data.dataset.': \n",
      "\t{'collate_fn': <function AtomsDataset.collate_forcefield at 0x2a3b2e4d0>, 'batch_size': 2, 'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x107f29510>, 'drop_last': True, 'num_workers': 0, 'pin_memory': False}\n",
      "2024-01-24 15:14:13,264 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset '<nfflr.data.dataset.': \n",
      "\t{'collate_fn': <function AtomsDataset.collate_forcefield at 0x2a3b2e4d0>, 'batch_size': 2, 'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x2aadad4b0>, 'drop_last': True, 'num_workers': 0, 'pin_memory': False}\n",
      "/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf07c663016546bca429b7ec74f4ad38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/690]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m training_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory()\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/nfflr/nfflr/train.py:278\u001b[0m, in \u001b[0;36mrun_train\u001b[0;34m(local_rank, config)\u001b[0m\n\u001b[1;32m    273\u001b[0m         val_evaluator\u001b[38;5;241m.\u001b[39madd_event_handler(\n\u001b[1;32m    274\u001b[0m             Events\u001b[38;5;241m.\u001b[39mCOMPLETED, \u001b[38;5;28;01mlambda\u001b[39;00m engine: session\u001b[38;5;241m.\u001b[39mreport(engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmetrics)\n\u001b[1;32m    275\u001b[0m         )\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting training loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_evaluator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:892\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:935\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:993\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:959\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 959\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    961\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/engine.py:1068\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/ignite/engine/__init__.py:112\u001b[0m, in \u001b[0;36msupervised_training_step.<locals>.update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_accumulation_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    111\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m gradient_accumulation_steps\n\u001b[0;32m--> 112\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m%\u001b[39m gradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    114\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/torch/autograd/function.py:264\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "training_config = {\n",
    "    \"dataset\": dataset,\n",
    "    \"model\": model,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"criterion\": ff_criterion,\n",
    "    \"random_seed\": 42,\n",
    "    \"batch_size\": 2,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"epochs\": 5,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"num_workers\": 0,\n",
    "    \"progress\": True,\n",
    "    \"output_dir\": tempfile.TemporaryDirectory().name\n",
    "}\n",
    "train.run_train(rank, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfflr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
