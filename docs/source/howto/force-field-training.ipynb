{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force field example\n",
    "\n",
    "## low level interface\n",
    "\n",
    "To show how the components of NFFLr work together, let's train a formation energy model using the `mlearn` dataset.\n",
    "We can use the `periodic_radius_graph` transform to configure the `AtomsDataset` to automatically transform atomic configurations into `DGLGraph`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bld/projects/nfflr/nfflr/atoms.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.positions = torch.tensor(positions, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=63, num_edges=838,\n",
       "       ndata_schemes={'coord': Scheme(shape=(3,), dtype=torch.float32), 'atomic_number': Scheme(shape=(), dtype=torch.int32)}\n",
       "       edata_schemes={'r': Scheme(shape=(3,), dtype=torch.float32)}),\n",
       " {'energy': tensor(-295.4975),\n",
       "  'forces': tensor([[-2.9819e+00,  6.0692e-01,  3.4814e+00],\n",
       "          [ 1.0296e+00, -1.3696e-01, -2.8213e-01],\n",
       "          [ 1.2912e+00,  2.5037e+00,  1.8027e-01],\n",
       "          [-5.0030e-01, -6.8284e-01, -2.6741e+00],\n",
       "          [-1.2477e+00,  5.4527e-01,  4.5055e-01],\n",
       "          [ 2.5866e-01, -1.2084e+00,  1.4178e+00],\n",
       "          [ 1.0119e+00, -9.7490e-01,  1.3844e+00],\n",
       "          [-1.1932e+00,  1.5503e+00, -2.9724e-01],\n",
       "          [ 9.7073e-01,  9.3589e-01,  5.8628e-03],\n",
       "          [-1.9438e-01,  7.4742e-01,  3.8357e-01],\n",
       "          [ 8.0306e-01, -4.9752e-01,  1.7991e+00],\n",
       "          [-2.0877e-01,  2.1184e-01,  1.6049e-03],\n",
       "          [ 1.1246e-01,  1.1640e-01,  2.1472e-02],\n",
       "          [-1.0178e+00, -3.9186e-02, -1.9705e-01],\n",
       "          [-1.1236e-01, -4.6998e-03, -5.7637e-01],\n",
       "          [ 9.8277e-01, -1.7129e+00,  5.8268e-01],\n",
       "          [-2.5929e-02, -6.0447e-01,  7.2930e-01],\n",
       "          [ 1.2310e-01,  1.2521e-01,  1.2171e-01],\n",
       "          [ 6.9789e-02, -1.1812e-01, -4.3184e-02],\n",
       "          [ 1.1590e+00,  2.4635e+00, -6.5856e-01],\n",
       "          [-2.1524e-01, -2.2756e+00, -5.4805e-01],\n",
       "          [ 5.5480e-01, -1.3885e+00, -2.1511e-01],\n",
       "          [ 1.6302e-01,  9.2803e-01,  4.1519e-01],\n",
       "          [ 3.4064e+00,  7.5014e-01,  1.3722e+00],\n",
       "          [-2.4695e+00, -1.2713e+00, -1.8288e+00],\n",
       "          [ 7.7516e-01, -4.2419e-01,  5.8298e-02],\n",
       "          [-3.8288e-01,  8.0085e-01, -1.6510e+00],\n",
       "          [ 1.5547e-01,  1.0354e+00,  4.0437e-01],\n",
       "          [ 6.4537e-01,  7.5504e-01,  2.2714e+00],\n",
       "          [ 8.1228e-01, -7.5641e-01,  5.9228e-03],\n",
       "          [ 4.3874e-01,  1.0936e+00,  7.3743e-02],\n",
       "          [-7.2079e-01, -1.9577e+00,  1.8561e-01],\n",
       "          [-9.5479e-01, -1.5858e+00, -1.2193e+00],\n",
       "          [-2.2785e+00,  5.2087e-01,  6.5478e-01],\n",
       "          [-1.8247e-01,  1.5047e-01, -7.9078e-01],\n",
       "          [ 5.5671e-01,  1.0329e+00, -1.3538e+00],\n",
       "          [ 4.9423e-01, -6.5522e-01, -4.5555e-01],\n",
       "          [-1.0316e+00, -9.6128e-01, -1.2571e+00],\n",
       "          [ 4.5952e-01,  1.0252e+00,  4.5242e-01],\n",
       "          [ 4.0851e-01, -3.0815e+00, -1.3960e+00],\n",
       "          [-6.7402e-02,  5.7674e-01, -4.0837e-01],\n",
       "          [ 1.4705e-01, -2.8501e-01,  9.3420e-02],\n",
       "          [ 1.3570e+00, -5.2225e-01,  1.4107e+00],\n",
       "          [ 1.2744e+00, -4.9754e-04,  6.7858e-01],\n",
       "          [ 7.5200e-02,  6.6578e-01,  6.6722e-01],\n",
       "          [-1.2814e-01,  1.0322e-01,  7.9861e-01],\n",
       "          [-7.1132e-01,  9.1106e-02, -4.0498e-01],\n",
       "          [-1.9249e-01, -2.9454e-01, -5.6467e-01],\n",
       "          [-2.3235e+00, -4.4552e-01,  5.5078e-01],\n",
       "          [ 2.7290e-01,  4.9336e-01,  1.7741e-02],\n",
       "          [-1.0562e-01,  2.6119e-01, -2.9145e-02],\n",
       "          [-7.9216e-01, -7.3487e-01, -7.2728e-01],\n",
       "          [-9.0055e-01,  1.1320e+00,  1.5074e+00],\n",
       "          [ 4.0955e-01,  5.8737e-01,  1.6214e-01],\n",
       "          [-4.1977e-01,  9.8810e-01, -9.6176e-03],\n",
       "          [ 3.6835e-02, -1.2254e-01,  2.0663e-01],\n",
       "          [-5.4287e-02,  2.2362e-01, -2.1434e-01],\n",
       "          [-1.7824e+00,  1.4063e+00, -2.2641e+00],\n",
       "          [-5.4766e-01, -1.3095e+00, -3.7692e-01],\n",
       "          [ 8.2991e-01, -6.9685e-02, -1.2885e-01],\n",
       "          [-6.6259e-01,  8.9111e-02,  1.3351e+00],\n",
       "          [ 1.2070e-01,  2.1746e-01,  9.2867e-03],\n",
       "          [ 3.1999e+00, -6.1232e-01, -3.3189e+00]]),\n",
       "  'stress': tensor([-6.5809, -9.6337, -2.7590,  9.0868, -1.6062, -5.4195]),\n",
       "  'volume': tensor(1182.2300)})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nfflr\n",
    "\n",
    "rcut = 4.0\n",
    "transform = nfflr.nn.PeriodicRadiusGraph(cutoff=rcut)\n",
    "dataset = nfflr.data.mlearn_dataset(\"Si\", transform=transform)\n",
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a medium-sized ALIGNN model, with atomic reference energies estimated from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'energy': tensor(0.4190, grad_fn=<SqueezeBackward0>),\n",
       " 'forces': tensor([[ 4.9852e-07, -1.3226e-07, -1.6838e-07],\n",
       "         [-2.6099e-07,  6.0730e-07, -1.0012e-07],\n",
       "         [-1.5601e-07,  1.8643e-07,  5.4123e-07],\n",
       "         [ 4.9777e-08, -4.2036e-08,  3.0614e-07],\n",
       "         [ 2.6156e-07,  2.6011e-08, -2.2906e-07],\n",
       "         [-2.5958e-07,  2.4926e-08, -1.5123e-07],\n",
       "         [-6.6287e-07,  3.5392e-08, -3.1768e-07],\n",
       "         [ 2.0246e-07, -1.4481e-07,  1.3680e-07],\n",
       "         [-3.6468e-07, -7.8529e-08, -2.0065e-07],\n",
       "         [-1.6847e-07, -5.5197e-07, -3.0397e-07],\n",
       "         [-4.4315e-07,  1.7318e-07, -2.7184e-07],\n",
       "         [-3.9167e-07, -4.3728e-07,  2.4780e-07],\n",
       "         [-1.0396e-07,  2.3536e-07,  3.7972e-07],\n",
       "         [ 1.0582e-07,  4.1403e-07,  9.9467e-08],\n",
       "         [ 1.7119e-07, -4.0077e-07,  1.0163e-07],\n",
       "         [-2.9991e-07,  1.8739e-07, -2.7835e-07],\n",
       "         [-1.6495e-07,  2.9263e-07, -4.5218e-07],\n",
       "         [-2.7957e-07, -3.9808e-08,  1.2410e-07],\n",
       "         [ 1.7630e-07,  1.5395e-07, -4.4017e-07],\n",
       "         [-3.3638e-07, -7.9677e-07, -3.0170e-08],\n",
       "         [-3.0897e-07,  3.3424e-07, -2.9252e-07],\n",
       "         [ 1.4767e-07,  1.0172e-06,  5.6851e-07],\n",
       "         [-5.3333e-08, -3.8543e-08, -2.1220e-07],\n",
       "         [-5.8495e-07, -3.2771e-07, -3.0228e-07],\n",
       "         [ 1.0645e-06, -9.4022e-08,  1.6639e-07],\n",
       "         [ 3.0766e-07,  1.4755e-07,  2.0958e-07],\n",
       "         [ 4.4681e-07, -2.0120e-07,  3.4926e-07],\n",
       "         [-3.4804e-07, -2.9582e-07,  5.2171e-08],\n",
       "         [-2.9326e-07, -3.1272e-07, -2.0422e-07],\n",
       "         [-6.8312e-07,  2.2691e-07,  5.7987e-08],\n",
       "         [ 4.2534e-07, -3.9441e-08, -7.5102e-08],\n",
       "         [-8.3759e-08,  7.2938e-07,  2.3605e-07],\n",
       "         [ 2.0615e-07,  3.3739e-07,  3.5826e-08],\n",
       "         [ 2.4221e-07, -3.6657e-07, -2.6233e-07],\n",
       "         [ 6.6346e-08, -1.9776e-07,  5.4219e-07],\n",
       "         [-3.8127e-07, -2.1177e-07,  2.3040e-07],\n",
       "         [-4.5862e-07,  1.1708e-07, -2.6635e-07],\n",
       "         [-9.1239e-08,  3.3130e-07, -2.1575e-07],\n",
       "         [-4.3628e-07, -4.8917e-07, -1.4185e-07],\n",
       "         [ 9.4668e-08,  6.6560e-07, -3.5026e-07],\n",
       "         [ 9.5468e-08, -2.4853e-07, -1.9127e-07],\n",
       "         [ 3.5211e-07, -2.1664e-08, -2.0985e-07],\n",
       "         [ 1.1645e-07, -2.7985e-07, -2.1464e-07],\n",
       "         [ 3.1087e-07,  5.3965e-07, -4.3247e-07],\n",
       "         [-7.2345e-08, -2.4828e-07,  2.1891e-07],\n",
       "         [-1.7479e-07, -4.0156e-07,  4.3426e-08],\n",
       "         [ 3.8896e-07, -1.7935e-07, -1.3259e-07],\n",
       "         [-3.7531e-08,  5.7780e-07, -7.0502e-07],\n",
       "         [ 5.6453e-07,  2.5741e-07,  4.2016e-07],\n",
       "         [-3.3870e-07, -4.0087e-07,  9.5696e-10],\n",
       "         [ 3.6085e-07,  7.3998e-08,  2.2403e-07],\n",
       "         [ 1.8033e-07,  2.6292e-07,  1.9867e-07],\n",
       "         [-3.8147e-10,  4.8288e-08, -1.6155e-07],\n",
       "         [ 2.2335e-07,  2.7076e-08,  5.3039e-08],\n",
       "         [ 2.5803e-07,  3.9612e-07,  4.6314e-09],\n",
       "         [ 8.7524e-08, -3.5744e-07,  5.0286e-07],\n",
       "         [-2.2405e-07,  4.5045e-07,  4.9179e-07],\n",
       "         [ 8.9257e-07, -9.0656e-07,  1.9939e-07],\n",
       "         [-3.9197e-07,  8.2639e-09,  6.3668e-08],\n",
       "         [ 6.6417e-07,  3.5491e-07,  5.0561e-07],\n",
       "         [ 5.4522e-08, -1.5173e-07, -1.6214e-07],\n",
       "         [-4.6770e-08, -4.1155e-07, -4.1902e-07],\n",
       "         [-1.1515e-07, -4.3381e-07,  5.8283e-07]], grad_fn=<MulBackward0>),\n",
       " 'stress': tensor([[[ 1.1601e-06, -1.9262e-08,  2.5061e-08],\n",
       "          [-1.9262e-08,  1.1291e-06,  2.3624e-08],\n",
       "          [ 2.5061e-08,  2.3624e-08,  1.1981e-06]]],\n",
       "        grad_fn=<SegmentReduceBackward>)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nfflr.models.gnn import alignn\n",
    "\n",
    "reference_energies = dataset.estimate_reference_energies()\n",
    "\n",
    "cfg = nfflr.models.ALIGNNConfig(\n",
    "    transform=transform,\n",
    "    cutoff=nfflr.nn.Cosine(rcut),\n",
    "    reference_energies=reference_energies,\n",
    "    alignn_layers=1, \n",
    "    gcn_layers=2, \n",
    "    embedding_features=16,\n",
    "    edge_input_features=16,\n",
    "    triplet_input_features=16,\n",
    "    hidden_features=32,\n",
    "    norm=\"layernorm\", \n",
    "    atom_features=\"embedding\",\n",
    "    compute_forces=True,\n",
    ")\n",
    "model = nfflr.models.ALIGNN(cfg)\n",
    "\n",
    "atoms, target = dataset[0]\n",
    "model(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=128, num_edges=1862,\n",
       "       ndata_schemes={'coord': Scheme(shape=(3,), dtype=torch.float32), 'atomic_number': Scheme(shape=(), dtype=torch.int32)}\n",
       "       edata_schemes={'r': Scheme(shape=(3,), dtype=torch.float32)}),\n",
       " {'energy': tensor([-339.0587, -346.9658]),\n",
       "  'n_atoms': tensor([64, 64]),\n",
       "  'forces': tensor([[-0.6067,  0.4133, -1.2317],\n",
       "          [ 1.1389, -2.1391, -1.2522],\n",
       "          [ 0.9383,  1.2495, -0.7030],\n",
       "          [-0.9375,  1.4090, -1.8885],\n",
       "          [ 1.9405, -1.5400, -1.0583],\n",
       "          [-0.7696, -0.0420,  0.8229],\n",
       "          [ 1.1848, -0.4141, -1.3028],\n",
       "          [ 0.2667,  1.0219,  0.3032],\n",
       "          [ 0.3974,  0.8765,  0.6913],\n",
       "          [-1.7408,  0.0886, -0.0915],\n",
       "          [-1.9527,  1.7243,  0.3515],\n",
       "          [ 0.4534,  1.4929, -0.4008],\n",
       "          [ 0.1687, -0.3284,  1.3564],\n",
       "          [ 0.0762, -0.4296,  0.0637],\n",
       "          [-0.3450,  0.2660,  0.0698],\n",
       "          [-0.3287, -0.7818,  2.3715],\n",
       "          [-1.1107, -2.1853,  0.5160],\n",
       "          [ 0.5564,  0.3952,  0.8598],\n",
       "          [ 0.5294, -0.2367,  1.5552],\n",
       "          [-0.8585, -1.7682, -0.3246],\n",
       "          [ 1.0090, -0.2278, -1.8685],\n",
       "          [-0.4690, -0.0778,  0.0649],\n",
       "          [-0.3530, -1.3482,  0.2470],\n",
       "          [-0.1369,  0.2853, -0.8246],\n",
       "          [-0.0419,  1.0469, -0.0269],\n",
       "          [-1.6209,  0.7013,  0.5656],\n",
       "          [-0.5838, -0.3524, -0.5539],\n",
       "          [ 1.1108,  2.1862, -0.9027],\n",
       "          [-0.4242,  0.2527,  0.4641],\n",
       "          [ 0.7320,  0.5011,  0.0990],\n",
       "          [ 1.4487, -0.1206,  0.0919],\n",
       "          [ 0.1224,  0.3211, -0.7926],\n",
       "          [ 1.0918, -0.2197,  1.3973],\n",
       "          [-0.3604, -1.6393, -0.6235],\n",
       "          [ 1.1438,  0.4187,  0.1493],\n",
       "          [ 0.6331,  1.2581, -0.1609],\n",
       "          [-0.2165, -0.2628, -0.9672],\n",
       "          [-0.1574, -0.3999, -1.5092],\n",
       "          [-1.0381,  0.8959, -0.4776],\n",
       "          [ 0.0427, -0.2871, -0.3567],\n",
       "          [-1.4407, -1.2312, -0.2968],\n",
       "          [ 1.4754, -1.6822,  1.9018],\n",
       "          [-0.5000,  1.4457, -0.9345],\n",
       "          [-0.0259,  0.7442,  0.8294],\n",
       "          [-1.4206,  0.2203, -0.3104],\n",
       "          [-0.0493,  0.3209, -0.2718],\n",
       "          [-0.2606,  0.4914, -0.7509],\n",
       "          [-0.5656, -0.5043, -0.2732],\n",
       "          [ 0.5072,  0.4810,  0.3144],\n",
       "          [ 0.6382, -1.2470, -1.9685],\n",
       "          [-0.0472, -1.8447,  0.7174],\n",
       "          [-0.7409, -2.2746,  1.4222],\n",
       "          [-0.3377, -0.0065, -0.1786],\n",
       "          [-0.4401, -0.4620,  0.1183],\n",
       "          [-0.3118,  0.2701, -0.6272],\n",
       "          [ 0.4956, -0.8331,  1.4242],\n",
       "          [-1.8694,  0.3687,  0.3444],\n",
       "          [ 0.3408,  0.6555,  1.2028],\n",
       "          [-0.2303,  0.7742,  0.9671],\n",
       "          [-0.7482,  0.6457, -0.6192],\n",
       "          [ 0.5277,  1.3264, -1.5282],\n",
       "          [ 1.5548, -0.1821,  0.6965],\n",
       "          [ 1.6107, -0.8165,  1.8468],\n",
       "          [ 0.9054,  1.3369,  1.2513],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000]]),\n",
       "  'stress': tensor([[ 3.7770, -0.2402, -1.9487, -5.4700, -7.5878,  0.6969],\n",
       "          [12.6918, 31.6262, 12.6918,  0.0000,  0.0000,  0.0000]])})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "batchsize = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batchsize, \n",
    "    collate_fn=dataset.collate, \n",
    "    sampler=SubsetRandomSampler(dataset.split[\"train\"]),\n",
    "    drop_last=True\n",
    ")\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up a PyTorch optimizer and objective function and optimize the model parameters with an explicit training loop. See the [PyTorch quickstart tutorial for more context)[https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html].\n",
    "\n",
    "For force field training, we use a custom loss function since the output of the model is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "100%|██████████| 107/107 [00:12<00:00,  8.63it/s]\n",
      "100%|██████████| 107/107 [00:11<00:00,  9.07it/s]\n",
      "100%|██████████| 107/107 [00:11<00:00,  9.22it/s]\n",
      "100%|██████████| 107/107 [00:11<00:00,  9.19it/s]\n",
      "100%|██████████| 107/107 [00:11<00:00,  9.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "criteria = {\"energy\": nn.MSELoss(), \"forces\": nn.HuberLoss(delta=5.0)}\n",
    "\n",
    "def ff_criterion(outputs, targets):\n",
    "    \"\"\"Specify combined energy and force loss.\"\"\"\n",
    "\n",
    "    n_atoms = targets[\"n_atoms\"]\n",
    "\n",
    "    # scale loss by crystal size\n",
    "    energy_loss = criteria[\"energy\"](\n",
    "        outputs[\"energy\"] / n_atoms, targets[\"energy\"] / n_atoms\n",
    "    )\n",
    "\n",
    "    # # scale the forces before the loss\n",
    "    force_scale = 1.0\n",
    "    force_loss = criteria[\"forces\"](outputs[\"forces\"], targets[\"forces\"])\n",
    "\n",
    "    return energy_loss + force_scale * force_loss\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "\n",
    "training_loss = []\n",
    "for epoch in range(5):\n",
    "    for step, (g, y) in enumerate(tqdm(train_loader)):\n",
    "        pred = model(g)\n",
    "        loss = ff_criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        training_loss.append(loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the ignite-based NFFLr trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from nfflr import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:25:24,547 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset '<nfflr.data.dataset.': \n",
      "\t{'collate_fn': <function AtomsDataset.collate_forcefield at 0x2a11ffa30>, 'batch_size': 2, 'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x1092a5f30>, 'drop_last': True, 'num_workers': 0, 'pin_memory': False}\n",
      "2024-02-15 09:25:24,547 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset '<nfflr.data.dataset.': \n",
      "\t{'collate_fn': <function AtomsDataset.collate_forcefield at 0x2a11ffa30>, 'batch_size': 2, 'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x2a21214e0>, 'drop_last': False, 'num_workers': 0, 'pin_memory': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bld/.pyenv/versions/3.10.9/envs/nfflr/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e5156f1725404f9f151508ee4ca217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/107]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab73d74f5579451399200d1c9c39e715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results - Epoch: 1  Avg loss: 12.75\n",
      "energy: 212.00  force: 1.0799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be178095ad26466cb73fbb7f73219b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/13]   8%|7          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val results - Epoch: 1  Avg loss: 11.93\n",
      "energy: 208.71  force: 1.4755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348ebfcbe5bc4e3dbe319c286014c7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/107]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f826800a36d84eda9cc4cf02bdcee881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results - Epoch: 2  Avg loss: 11.00\n",
      "energy: 190.98  force: 0.4300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e7522b1d2b4a6ea26b5ad8da694787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/13]   8%|7          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val results - Epoch: 2  Avg loss: 9.04\n",
      "energy: 186.25  force: 0.5094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68f7289b91f406682f702a38d70b5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/107]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99a4e593ef24a4195186f2c067af032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results - Epoch: 3  Avg loss: 9.58\n",
      "energy: 196.33  force: 0.4276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563e614e784b4f1ab71de0b543efae9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/13]   8%|7          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val results - Epoch: 3  Avg loss: 8.00\n",
      "energy: 172.12  force: 0.5229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478d22ef03354dcfa9ff5e4cdd75e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/107]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaf0276f03f4c669ab763e2936d9a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results - Epoch: 4  Avg loss: 8.01\n",
      "energy: 175.88  force: 0.3954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccb212ba1754fda8b1950f188d7c510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/13]   8%|7          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val results - Epoch: 4  Avg loss: 7.42\n",
      "energy: 165.89  force: 0.4320\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eae99d2ef1844368fa2bbdbb2158456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/107]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10ef4fcca14497d9ef112ce108ab8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results - Epoch: 5  Avg loss: 8.32\n",
      "energy: 172.06  force: 0.4186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88b587b44184b788f5e56718fda0d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/13]   8%|7          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val results - Epoch: 5  Avg loss: 7.36\n",
      "energy: 165.02  force: 0.4125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.359944857083834"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = 0\n",
    "training_config = {\n",
    "    \"dataset\": dataset,\n",
    "    \"model\": model,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"criterion\": ff_criterion,\n",
    "    \"random_seed\": 42,\n",
    "    \"batch_size\": 2,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"epochs\": 5,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"num_workers\": 0,\n",
    "    \"progress\": True,\n",
    "    \"output_dir\": tempfile.TemporaryDirectory().name\n",
    "}\n",
    "train.run_train(rank, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfflr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
